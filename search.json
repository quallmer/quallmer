[{"path":"https://seraphinem.github.io/quallmer/articles/getting-started.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic usage","title":"Getting started with quallmer","text":"quallmer package developed using R. Please make sure recent version R RStudio installed computer. new R RStudio, can find great free--charge 1.5h introduction R RStudio instats. get started quallmer, first need install package GitHub. , can load package begin using functions.","code":"# If you don't have pak installed yet, uncomment and run the following line: # install.packages(\"pak\") # Then, install quallmer using pak: pak::pak(\"SeraphineM/quallmer\") library(quallmer) #> Loading required package: ellmer"},{"path":"https://seraphinem.github.io/quallmer/articles/getting-started.html","id":"overview-of-tutorials","dir":"Articles","previous_headings":"","what":"Overview of tutorials","title":"Getting started with quallmer","text":"using large language models, users need sign API key LLM provider, openai, download open-source model like Ollama. quallmer package supports multiple LLM providers ellmer package, allowing users choose one best fits needs. Using annotate(), users can generate structured, interpretable outputs powered large language models (LLMs). package includes library predefined tasks common qualitative coding needs, sentiment analysis, thematic coding, stance detection. also allows users create custom annotation tasks tailored specific research questions data types using task(). tutorials guide following topics: Signing OpenAI API key: tutorial guide process obtaining API key OpenAI, necessary using OpenAI’s LLMs quallmer package. Working open-source Ollama model: tutorial demonstrate use quallmer package open-source Ollama model qualitative coding tasks. Using predefined tasks: illustrations show utilize library predefined annotation tasks available quallmer package perform common qualitative coding tasks efficiently. Creating custom tasks: tutorial walk process defining custom annotation tasks using task() function, allowing tailor LLM’s output specific research needs. Using Agreement App: tutorial introduce Agreement App manually code data, check LLM annotations, calculate interrater reliability user-friendly intuitive interface. hope tutorials help get started quallmer package empower leverage large language models qualitative research projects!","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/overview.html","id":"predefined-tasks","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Predefined tasks","title":"Overview of predefined tasks","text":"quallmer package currently includes following predefined tasks: wish create custom tasks tailored specific research questions data types, can use task() function. function allows specify system prompt output structure, enabling customize annotation process according needs. tutorial create custom tasks, please refer custom tasks tutorial.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_fact.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Fact checking of claims","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The three most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[57:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_fact.html","id":"using-annotate-for-fact-checking-of-claims-in-texts","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for fact checking of claims in texts","title":"Example: Fact checking of claims","text":"text political speech, often includes aspirational rhetorical statements rather factual claims. Transfer Power: claim transferring power ‘back people’ subjective lacks specific evidence. Economic Claims: Statements factories closing wealth redistribution broad fully supported data. Foreign Policy: Assertions enriching foreign industries expense American ones oversimplified. Crime Poverty: Descriptions ‘American carnage’ inner-city conditions exaggerated universally accurate. Unity Division: speech emphasizes unity, political context may suggest otherwise.","code":"# Apply predefined fact checking task with task_fact() in the annotate() function result <- annotate(data_corpus_inaugural, task = task_fact(),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Fact-checking' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_fact.html","id":"using-annotate-for-fact-checking-with-a-specific-number-of-claims-to-check","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for fact checking with a specific number of claims to check","title":"Example: Fact checking of claims","text":"speech contains several misleading inaccurate claims. Historical Inaccuracies: statement Panama Canal management misleading. canal transferred Panama 1999 treaty signed 1977, operated China. Policy Claims: speech includes numerous policy promises claims either exaggerated feasible, changing name Gulf Mexico declaring national energy emergency immediately solve inflation. Election Results: claim winning seven swing states popular vote millions lacks context verification, presented without evidence specific details. example, demonstrated use annotate() function task_fact() fact-check claims corpus innaugural speeches. results include truth score, identified misleading topics, explanations claim evaluated. amount claims check can adjusted using max_topics parameter task_fact() function. Now can apply approach texts fact-checking purposes!","code":"# Apply predefined fact checking task with task_fact() in the annotate() function result_claims <- annotate(data_corpus_inaugural, task = task_fact(max_topics = 3),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Fact-checking' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_ideology.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Ideology detection","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The three most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[57:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_ideology.html","id":"using-annotate-for-ideological-scaling-of-texts","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for ideological scaling of texts","title":"Example: Ideology detection","text":"","code":"# Define ideological dimension dimension <- \"inclusive–exclusive\" # Provide definition for the dimension definition <- \"Inclusive language emphasizes equal rights, diversity, pluralism,  and protection of minorities, whereas exclusive language emphasizes exclusion  of groups, national homogeneity, and restricting rights.\" # Apply predefined ideology task with task_ideology() in the annotate() function result <- annotate(data_corpus_inaugural, task = task_ideology(dimension, definition),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Ideological scaling' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_ideology.html","id":"adjusting-the-ideology-scaling-task","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Adjusting the ideology scaling task","title":"Example: Ideology detection","text":"can customize ideological scaling task defining task task() (detailed explanation, see “Defining custom tasks” tutorial). example, might like change scale 0-10 -5 +5. example, demonstrated use task_ideology() scaling texts regarding ideological position specified dimension. also showed customize task using task() function tailored annotation needs, e.g., changing scale 0-10 -5 +5. Now can apply techniques text data ideological analysis!","code":"custom_ideology <- task(     name = \"Ideological scaling\",     system_prompt = paste0(       \"You are an expert political scientist performing ideological text scaling.\",       \"Task:\",       \"- Read each short text carefully.\",       \"- Place the text on a -5 to +5 scale for the following ideological dimension: \",       dimension,        definition     ),     type_def = ellmer::type_object(       score       = ellmer::type_integer(\"Ideological position on the specified dimension (0–10, where -5 = first pole, +5 = second pole)\"),       explanation = ellmer::type_string(\"Brief justification for the assigned score, referring to specific elements in the text\")     ),     input_type = \"text\"   ) # Apply the custom task custom_result <- annotate(data_corpus_inaugural, task = custom_ideology,                            chat_fn = chat_openai, model = \"gpt-4o\",                           api_args = list(temperature = 0)) ## Running task 'Ideological scaling' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_salience.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Salience of topics","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The three most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[57:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_salience.html","id":"using-annotate-for-salience-of-any-topics-discussed-in-texts","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for salience of ANY topics discussed in texts","title":"Example: Salience of topics","text":"American Values Ideals: speech frequently references foundational American principles liberty, equality, democracy, emphasizing enduring importance. Equality Civil Rights: strong focus equality, references historical movements ongoing journey towards equal rights citizens, including women, LGBTQ+ individuals, immigrants. Collective Action Unity: text emphasizes need unity collective action address modern challenges, highlighting importance working together nation. Economic Social Progress: speech discusses economic recovery, importance strong middle class, need social programs like Medicare Social Security. Role Government: discussion role government ensuring fair play market, protecting citizens, adapting new challenges, maintaining skepticism central authority. 2017-Trump Transfer Power People , America First Policy , National Unity Patriotism , Economic Rebuilding Job Creation, Critique Political Establishment Transfer Power People: speech emphasizes returning power Washington citizens, highlighting central theme. America First Policy: repeated focus prioritizing American interests trade, immigration, foreign affairs underscores topic’s prominence. National Unity Patriotism: call unity patriotism, along references shared American values, key theme. Economic Rebuilding Job Creation: speech discusses rebuilding infrastructure creating jobs, making significant focus. Critique Political Establishment: Criticism political establishment failures recurring element, highlighting importance text. 2021-Biden Unity , Democracy , Challenges facing America , American values ideals , Historical context legacy Unity: speech emphasizes unity central theme, repeatedly calling Americans come together face challenges heal divisions. Democracy: Democracy highlighted precious fragile cause prevailed, references peaceful transfer power people. Challenges facing America: text discusses various challenges pandemic, racial justice, political extremism, climate change, emphasizing need address issues. American values ideals: speech frequently references values like liberty, dignity, truth, framing core American identity future. Historical context legacy: numerous references historical events figures, Civil War past presidents, provide context inspiration current efforts. 2025-Trump American Renewal Greatness , Government Reform Efficiency , National Security Immigration , Economic Policies Energy Independence, Unity National Pride American Renewal Greatness: speech emphasizes new era America, focusing making country respected prosperous , repeated references ‘golden age’ national success. Government Reform Efficiency: significant emphasis reforming government structures, ending corruption, restoring trust, including creation new departments executive orders. National Security Immigration: speaker discusses securing borders, ending illegal immigration, designating cartels terrorist organizations, highlighting national security top priority. Economic Policies Energy Independence: speech outlines plans economic revival, including energy independence, ending Green New Deal, revitalizing manufacturing. Unity National Pride: speaker frequently mentions national unity, pride, collective spirit Americans, aiming inspire unify nation. Health: text emphasizes impact pandemic, mentioning virus major challenge need face nation. highlighted references number lives lost call unity overcome . Foreign Policy: clear focus America’s role world, mentions repairing alliances engaging globally, indicating commitment international relations. Economy: text discusses job losses economic challenges, emphasizing need rebuild middle class create jobs, highlights economic concerns. Environment: mention “cry survival planet” climate crisis indicates environmental issues significant concern. Education: Briefly mentioned context teaching children safe schools, indicating importance broader discussion national priorities. 2025-Trump foreign policy, economy , health , environment , education Foreign Policy: text frequently discusses international relations, border security, actions foreign entities, emphasizing importance America’s global standing actions like reclaiming Panama Canal. Economy: Economic issues highlighted mentions inflation, energy policies, manufacturing, tariffs, indicating focus economic revitalization. Health: references public health system commitment ending chronic disease epidemic, showing concern health-related issues. Environment: text mentions ending Green New Deal energy policies like drilling, relate environmental topics. Education: education system criticized teaching children ashamed, indicating focus educational reform.","code":"# Apply predefined salience task with task_salience() in the annotate() function result <- annotate(data_corpus_inaugural, task = task_salience(),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Salience (ranked topics)' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 2 -> 2 | ■■■■■■■■■■■■■■■■                  50% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # Define a list of topics to focus on topics <- c(\"economy\", \"health\", \"education\", \"environment\", \"foreign policy\") # Apply predefined salience task with task_salience() in the annotate() function result <- annotate(data_corpus_inaugural, task = task_salience(topics),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Salience (ranked topics)' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_salience.html","id":"adjusting-the-task_salience-so-it-also-returns-the-stance-for-each-topic","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Adjusting the task_salience() so it also returns the stance for each topic","title":"Example: Salience of topics","text":"example, demonstrated use task_salience() identifying ranking topics discussed texts, without predefined list topics. Additionally, showed customize task include stance classification topic. showcases flexibility annotate() function task framework quallmer various text analysis tasks.","code":"# Customizing the task to include the stance for each topic custom_task <- task(   name = \"Salience and stance of topics\",   system_prompt = paste(     \"You are an expert analysing the content of texts.\",     \"\",     \"Task:\",     \"- Read the text carefully.\",     \"- Identify and rank the salience of the following topics: economy, health, education, environment, foreign policy.\",     \"- For each topic mentioned, assign a stance as one of the following:\",     \"  pro, neutral, or contra.\",     \"- Append the stance directly after each topic name in the form 'topic: stance'.\",     \"- Return all topic:stance entries in descending order of salience.\",     \"- Separate entries with commas when presenting them in a list.\",     \"\",     \"Do not infer information that is not in the text.\",     \"Base all evaluations solely on the language and arguments in the document.\",     \"\",     \"Output:\",     \"- `topic_stance`: a ranked list of topic labels with stance labels appended (e.g., 'economy: pro', 'health: contra').\",     \"- `explanation`: a brief justification explaining why the topics were ordered and how stance was determined.\",     sep = \"\\n\"   ),   type_def = ellmer::type_object(     topic_stance = ellmer::type_array(       ellmer::type_string(\"Topic and stance label combined (e.g., 'economy: pro'), ranked by salience.\")     ),     explanation = ellmer::type_string(       \"Brief justification for the salience ordering and stance classification.\"     )   ),   input_type = \"text\" )  # Apply the customized task in the annotate() function custom_result <- annotate(data_corpus_inaugural, task = custom_task,                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Salience and stance of topics' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_sentiment.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Sentiment analysis","text":"","code":"library(quallmer) ## Loading required package: ellmer #Example texts texts <- c( \"This is wonderful!\", \"I really dislike this approach.\", \"The results are somewhat disappointing.\", \"Absolutely fantastic work!\" )"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_sentiment.html","id":"using-annotate-for-predefined-sentiment-analysis-of-texts","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for predefined sentiment analysis of texts","title":"Example: Sentiment analysis","text":"","code":"# Apply predefined sentiment task with task_sentiment() in the annotate() function result <- annotate(texts, task = task_sentiment(),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Sentiment analysis' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_sentiment.html","id":"adjusting-the-sentiment-task","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Adjusting the sentiment task","title":"Example: Sentiment analysis","text":"can customize sentiment analysis task defining task task() (detailed explanation, see “Defining custom tasks” tutorial). example, might want include additional field confidence level. , might want change scoring scale 5-point Likert scale. way, can easily adapt sentiment analysis task fit specific research needs!","code":"custom_sentiment <- task(   name = \"Custom sentiment analysis\",   system_prompt = \"You are an expert annotator. Rate the sentiment of each text from -1 (very negative) to 1 (very positive), briefly explain why, and provide a confidence level from 0 to 1.\",   type_def = ellmer::type_object(     score = ellmer::type_number(\"Sentiment score between -1 (very negative) and 1 (very positive)\"),     explanation = ellmer::type_string(\"Brief explanation of the rating\"),     confidence = ellmer::type_number(\"Confidence level from 0 to 1\")   ),   input_type = \"text\" ) # Apply the custom sentiment task custom_result <- annotate(texts, task = custom_sentiment,                            chat_fn = chat_openai, model = \"gpt-4o\",                           api_args = list(temperature = 0)) ## Running task 'Custom sentiment analysis' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% likert_sentiment <- task(   name = \"Likert scale sentiment analysis\",   system_prompt = \"You are an expert annotator. Rate the sentiment of each text on a scale from 1 (very negative) to 5 (very positive) and briefly explain why.\",   type_def = ellmer::type_object(     score = ellmer::type_number(\"Sentiment score between 1 (very negative) and 5 (very positive)\"),     explanation = ellmer::type_string(\"Brief explanation of the rating\")   ),   input_type = \"text\" ) # Apply the Likert scale sentiment task likert_result <- annotate(texts, task = likert_sentiment,                            chat_fn = chat_openai, model = \"gpt-4o\",                           api_args = list(temperature = 0)) ## Running task 'Likert scale sentiment analysis' using model: gpt-4o"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_stance.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Stance detection","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The three most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[57:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_stance.html","id":"using-annotate-for-stance-detection-of-texts","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Using annotate() for stance detection of texts","title":"Example: Stance detection","text":"","code":"# Define topic of interest topic <- \"Climate Change\" # Apply predefined stance task with task_stance() in the annotate() function result <- annotate(data_corpus_inaugural, task = task_stance(topic),                     chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Stance detection' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_stance.html","id":"adjusting-the-stance-detection-task","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Adjusting the stance detection task","title":"Example: Stance detection","text":"can customize stance detection task defining task task() (detailed explanation, see “Defining custom tasks” tutorial). example, might want include additional field confidence level. , might want LLM extract specific arguments supporting stance. Acknowledges threat climate change need respond protect future generations. Emphasizes importance leading transition sustainable energy sources maintain economic vitality. Recognizes scientific consensus climate change impact environmental disasters. speech emphasizes economic growth job creation without mentioning environmental concerns. focus national pride infrastructure development, reference climate change. speech prioritizes American interests industries, discuss sustainability environmental impact. speech identifies climate change one major challenges facing nation, alongside significant issues like pandemic systemic racism. calls unity boldness addressing challenges, implying proactive stance climate action. mention ‘cry survival comes planet ’ highlights urgency importance addressing climate change. speaker declares end Green New Deal, indicating opposition climate change policies. Emphasizes increased drilling fossil fuel use, contradicts efforts reduce carbon emissions. Revokes electric vehicle mandate, step back reducing reliance fossil fuels. example, demonstrated use stance() task stance detection texts regarding “Climate Change”. also showed customize task include additional fields confidence level key arguments supporting stance. Now turn explore stance detection texts topics interest!","code":"custom_stance <- task(   name = \"Custom stance detection\",   system_prompt = paste0(     \"You are an expert annotator. Read each short text carefully and determine its stance towards \",     topic,     \". Classify the stance as Pro, Neutral, or Contra, provide a brief explanation for your classification, and indicate your confidence level from 0 to 1.\"   ),   type_def = ellmer::type_object(     stance = ellmer::type_string(\"Stance towards the topic: Pro, Neutral, or Contra\"),     explanation = ellmer::type_string(\"Brief explanation of the classification\"),     confidence = ellmer::type_number(\"Confidence level from 0 to 1\")   ),   input_type = \"text\" ) # Apply the custom stance task custom_result <- annotate(data_corpus_inaugural, task = custom_stance,                            chat_fn = chat_openai, model = \"gpt-4o\",                           api_args = list(temperature = 0)) ## Running task 'Custom stance detection' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% argument_stance <- task(   name = \"Argument-based stance detection\",   system_prompt = paste0(     \"You are an expert annotator. Read each short text carefully and determine its stance towards \",     topic,     \". Classify the stance as Pro, Neutral, or Contra, provide a brief explanation for your classification, and list up to three key arguments supporting the stance.\"   ),   type_def = ellmer::type_object(     stance = ellmer::type_string(\"Stance towards the topic: Pro, Neutral, or Contra\"),     explanation = ellmer::type_string(\"Brief explanation of the classification\"),     arguments = ellmer::type_string(\"Key arguments supporting the stance\")   ),   input_type = \"text\" ) # Apply the argument-based stance task argument_result <- annotate(data_corpus_inaugural, task = argument_stance,                              chat_fn = chat_openai, model = \"gpt-4o\",                             api_args = list(temperature = 0)) ## Running task 'Argument-based stance detection' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/agreement.html","id":"launching-the-agreement-app","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Launching the Agreement App","title":"Using the Agreement App","text":"launch Agreement App, can use agreement_app() function quallmer package. Make sure package loaded R environment. , simply call agreement_app() function. open Agreement App new window tab web browser.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/agreement.html","id":"using-the-agreement-app-for-manual-coding","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Using the Agreement App for manual coding","title":"Using the Agreement App","text":"Agreement App launched, can start uploading dataset. app supports .csv .rds file formats. uploading data, can select column containing content (e.g., texts, images, etc.) want manually assess. using app, can manually assign score comments text item based coding scheme. can also save example sentences text item help remember coding decisions later illustrative examples research.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/agreement.html","id":"reviewing-llm-generated-annotations","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Reviewing LLM-generated annotations","title":"Using the Agreement App","text":"previously used quallmer package generate annotations using large language models (LLMs), can upload annotations Agreement App review. app allows check LLM-generated codes alongside justifications provided model. can decide whether accept annotations valid invalid, modify based assessment adding comments example sentences.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/agreement.html","id":"calculating-agreement-scores-such-as-krippendorffs-alpha-or-fleiss-kappa","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Calculating agreement scores such as Krippendorff’s alpha or Fleiss’ kappa","title":"Using the Agreement App","text":"completing manual coding reviewing LLM-generated annotations, Agreement App provides functionality calculate intercoder reliability scores. can choose various metrics, Krippendorff’s alpha Fleiss’ kappa, assess agreement different coders manual codes LLM annotations , shown , multiple LLM runs.  app provides intuitive interface navigating data making coding decisions. coding decisions saved automatically, find newly created folder named “agreement” working directory.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Loading packages and data","title":"Defining custom tasks","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The three most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[57:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html","id":"defining-a-custom-prompt","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Defining a custom prompt","title":"Defining custom tasks","text":"Defining prompts crucial step creating custom tasks. prompt guides LLM interpret input data kind output generate. example, create prompt instructs LLM score documents based alignment political left ideologies. Prompts can much longer complex depending task hand. Prompts clear specific ensure LLM understands task requirements.","code":"prompt <- \"Score the following document on a scale of how much it aligns with the political left. The political left is defined as groups which advocate for social equality, government intervention in the economy, and progressive policies. Use the following metrics: SCORING METRIC: 3 : extremely left 2 : very left 1 : slightly left 0 : not at all left\""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html","id":"defining-the-structure-of-the-response-with-define_task","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Defining the structure of the response with define_task()","title":"Defining custom tasks","text":"task() function allows us specify expected structure LLM’s response. following important arguments users need specify: name: descriptive name task. system_prompt: prompt guides LLM perform task. type_def: Defines expected structure response using ellmers type specifications type_object(), type_array(), etc. information use ellmer’s type specifications, please refer ellmer documentation type specifications.","code":"# Define the custom task using task() ideology_scores <- task(   name = \"Score Political Left Alignment\",   system_prompt = prompt,   type_def = type_object(     score = type_number(\"Score\"),     explanation = type_string(\"Explanation\")   ),   input_type = \"text\" )"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html","id":"applying-the-custom-task-to-the-corpus","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Applying the custom task to the corpus","title":"Defining custom tasks","text":"step similar applying predefined tasks using annotate() function. , use annotate() function apply custom task sample corpus inaugural speeches. specify LLM use (case, openai’s gpt-4o model) additional API arguments needed. example, set temperature 0 deterministic outputs, improving consistency scoring across multiple runs therefore increasing reliability. Now successfully created applied custom annotation task using quallmer package! can modify prompt response structure suit specific research needs.","code":"# Apply the custom task to the inaugural speeches corpus result <- annotate(data_corpus_inaugural, task = ideology_scores,                    chat_fn = chat_openai, model = \"gpt-4o\",                    api_args = list(temperature = 0)) ## Running task 'Score Political Left Alignment' using model: gpt-4o ## [working] (0 + 0) -> 3 -> 1 | ■■■■■■■■■                         25% ## [working] (0 + 0) -> 0 -> 4 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"precautions","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Precautions","title":"Signing up for an openai API key","text":"Closed LLMs OpenAI’s GPT-4o free use require subscription. also come ethical concerns risks, especially comes data privacy security. Therefore, always aware data use potential consequences analysis make sure enable necessary safeguards protect privacy security. addition, aware license use OpenAI models comes along adhering specific regulations avoid misuse. Therefore, always aware data use potential consequences analysis make sure enable necessary safeguards protect privacy security.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"setting-up-an-api-key-for-openai-models","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Setting up an API key for openai models","title":"Signing up for an openai API key","text":"openai API provides access various called closed models (fee-based, open-source). services available (example, Claude Google Gemini, etc.) require slightly different set-ups. can find information pricing openai .","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"to-use-the-openai-api-please-follow-these-steps","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Setting up an API key for openai models","what":"To use the openai API, please follow these steps:","title":"Signing up for an openai API key","text":"Go openai playground: https://platform.openai.com/playground> Click Sign top right corner Fill details confirm Sign Click now Settings icon top right corner Go Billing provide billing information (otherwise won’t work!) billing information complete, can create new project (top left corner, click Default Project) Click Dashboard top right corner Click API keys left side panel bottom Click Create new secret key Copy key close window copied key, save somewhere safe accessible. security reasons, won’t able view openai account. lose , need regenerate . Keep API key safe share others. suspect key compromised, can regenerate dashboard. aware charged usage API via key.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"configuring-your-openai-api-key-in-rstudio","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Setting up an API key for openai models","what":"Configuring your openai API key in RStudio","title":"Signing up for an openai API key","text":"interact openai API, ’s required valid OPENAI_API_KEY environment variable R. can establish environment variable globally including -called .Renviron file. approach ensures environment variable persists across R sessions Shiny app runs background. set commands open .Renviron file modification: Add following line .Renviron, replacing “APIKEY” actual API key: OPENAI_API_KEY=“APIKEY”. need restart R session changes take effect. can clicking Session menu RStudio selecting Restart R. Caution: ’re using version control systems like GitHub GitLab, remember include .Renviron .gitignore file prevent exposing API key! maintain privacy data using gptstudio, highlight, include prompt, otherwise upload sensitive data, code, text remain confidential. Now ready use openai models quallmer package! example, can test setup running example sentiment analysis.","code":"require(usethis) edit_r_environ()"},{"path":"https://seraphinem.github.io/quallmer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Seraphine F. Maerz. Author, maintainer. Kenneth Benoit. Author.","code":""},{"path":"https://seraphinem.github.io/quallmer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Maerz S, Benoit K (2025). quallmer: Qualitative analysis large language models. R package version 0.1.0, https://SeraphineM.github.io/quallmer.","code":"@Manual{,   title = {quallmer: Qualitative analysis with large language models},   author = {Seraphine F. Maerz and Kenneth Benoit},   year = {2025},   note = {R package version 0.1.0},   url = {https://SeraphineM.github.io/quallmer}, }"},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"quallmer-","dir":"","previous_headings":"","what":"Qualitative analysis with large language models","title":"Qualitative analysis with large language models","text":"quallmer package easy--use toolbox qualitative researchers quickly apply AI-assisted annotation texts, images, pdfs, tabular data structured data. Using annotate(), users can generate structured, interpretable outputs powered large language models (LLMs). package includes library predefined tasks common qualitative coding needs, sentiment analysis, thematic coding, stance detection. also allows users create custom annotation tasks tailored specific research questions data types using task(). ensure quality reliability AI-generated annotations, quallmer offers tools comparing LLM outputs human-coded data assessing inter-coder reliability. agreement(), users can launch interactive app manually code data, review AI annotations, evaluate intercoder reliability coders agreement LLM-generated scores. quallmer package makes AI-assisted qualitative coding accessible without requiring deep expertise R, programming machine learning.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"included-functions","dir":"","previous_headings":"","what":"Included functions","title":"Qualitative analysis with large language models","text":"package provides following core functions:","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"annotate","dir":"","previous_headings":"","what":"annotate()","title":"Qualitative analysis with large language models","text":"generic function works LLM supported ellmer. Generates structured responses based predefined user-defined tasks.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"task","dir":"","previous_headings":"","what":"task()","title":"Qualitative analysis with large language models","text":"Creates custom annotation tasks tailored specific research questions data types. Uses system_prompt various type specifications ellmer package define LLM interpret inputs format outputs. Tasks created task() can passed directly annotate(). allows users tailor annotation process specific data types makes package extensible future use cases.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"agreement_app","dir":"","previous_headings":"","what":"agreement_app()","title":"Qualitative analysis with large language models","text":"Manually code data Review validate LLM-generated annotations Compare human-coded data LLM-generated annotations evaluate agreement inter-coder reliability.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"supported-llms","dir":"","previous_headings":"","what":"Supported LLMs","title":"Qualitative analysis with large language models","text":"package supports LLMs currently available ellmer package. authentication usage LLMs, please refer respective ellmer documentation see tutorial setting openai API key getting started open-source Ollama model.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Qualitative analysis with large language models","text":"can install development version quallmer https://github.com/SeraphineM/quallmer :","code":"# install.packages(\"pak\") pak::pak(\"SeraphineM/quallmer\")"},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"example-use-and-tutorials","dir":"","previous_headings":"","what":"Example use and tutorials","title":"Qualitative analysis with large language models","text":"learn use package, please refer step--step tutorials illustrations use predefined tasks.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/agreement_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch the Agreement App — agreement_app","title":"Launch the Agreement App — agreement_app","text":"Starts Shiny app manual coding, LLM checking, agreement calculation. - LLM mode, can also select metadata columns. - Agreement mode, select unit ID coder columns (text column).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/agreement_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch the Agreement App — agreement_app","text":"","code":"agreement_app()"},{"path":"https://seraphinem.github.io/quallmer/reference/agreement_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch the Agreement App — agreement_app","text":"shiny.appobj","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply an annotation task to input data — annotate","title":"Apply an annotation task to input data — annotate","text":"Automatically detects correct task type (e.g., text, image). Delegates actual processing task's internal run() method.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply an annotation task to input data — annotate","text":"","code":"annotate(.data, task, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply an annotation task to input data — annotate","text":".data Input data (text, image, etc.) task task created [task()] ... Additional arguments passed task$run()","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply an annotation task to input data — annotate","text":"Structured data frame results","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/quallmer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"quallmer: Qualitative analysis with large language models — quallmer-package","title":"quallmer: Qualitative analysis with large language models — quallmer-package","text":"Provides userfriendly support qualitative analysis large language models (LLMs).","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/quallmer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"quallmer: Qualitative analysis with large language models — quallmer-package","text":"Maintainer: Seraphine F. Maerz seraphine.maerz@unimelb.edu.au (ORCID) Authors: Kenneth Benoit kbenoit@smu.edu.sg (ORCID)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":null,"dir":"Reference","previous_headings":"","what":"Define an annotation task — task","title":"Define an annotation task — task","text":"flexible task definition wrapper ellmer. Supports structured output type, including `type_object()`, `type_array()`, `type_enum()`, `type_boolean()`, others.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define an annotation task — task","text":"","code":"task(name, system_prompt, type_def, input_type = \"text\")"},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define an annotation task — task","text":"name Name task. system_prompt System prompt guide model (required ellmer's `chat_fn`). type_def Structured output definition, e.g., created `ellmer::type_object()`, `ellmer::type_array()`, `ellmer::type_enum()`. input_type Type input data: `\"text\"`, `\"image\"`, `\"audio\"`, etc.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define an annotation task — task","text":"task object `run()` method.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_fact.html","id":null,"dir":"Reference","previous_headings":"","what":"Predefined task for overall truthfulness assessment — task_fact","title":"Predefined task for overall truthfulness assessment — task_fact","text":"Assigns overall truthfulness score text lists topics reduce confidence accuracy.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_fact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predefined task for overall truthfulness assessment — task_fact","text":"","code":"task_fact(max_topics = 5)"},{"path":"https://seraphinem.github.io/quallmer/reference/task_fact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predefined task for overall truthfulness assessment — task_fact","text":"max_topics Integer: maximum number topics issues list reducing confidence truthfulness text. Default 5.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_fact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predefined task for overall truthfulness assessment — task_fact","text":"task object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_ideology.html","id":null,"dir":"Reference","previous_headings":"","what":"Predefined task for ideological scaling on a specified dimension — task_ideology","title":"Predefined task for ideological scaling on a specified dimension — task_ideology","text":"Ideological scaling specified dimension, justification.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_ideology.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predefined task for ideological scaling on a specified dimension — task_ideology","text":"","code":"task_ideology(   dimension = \"the specified ideological dimension (0 = first pole, 10 = second pole)\",   definition = NULL )"},{"path":"https://seraphinem.github.io/quallmer/reference/task_ideology.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predefined task for ideological scaling on a specified dimension — task_ideology","text":"dimension character string specifying ideological dimension, ideally naming poles, e.g., \"liberal - illiberal\", \"left - right\", \"inclusive - exclusive\". first pole corresponds 0 second 10. definition Optional detailed explanation dimension means. provided, included system prompt guide annotation.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_ideology.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predefined task for ideological scaling on a specified dimension — task_ideology","text":"task object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_salience.html","id":null,"dir":"Reference","previous_headings":"","what":"Predefined task for salience of topics discussed (ranked topics) — task_salience","title":"Predefined task for salience of topics discussed (ranked topics) — task_salience","text":"Ranked list topics mentioned text, ordered salience.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_salience.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predefined task for salience of topics discussed (ranked topics) — task_salience","text":"","code":"task_salience(topics = NULL, max_topics = 5)"},{"path":"https://seraphinem.github.io/quallmer/reference/task_salience.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predefined task for salience of topics discussed (ranked topics) — task_salience","text":"topics Optional character vector predefined topic labels (e.g., c(\"economy\", \"health\", \"education\", \"environment\")). supplied, model classify rank among topics. NULL, model may infer topic labels directly text. max_topics Integer: maximum number topics return topics inferred text. Default 5.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_salience.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predefined task for salience of topics discussed (ranked topics) — task_salience","text":"task object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Predefined task for sentiment analysis — task_sentiment","title":"Predefined task for sentiment analysis — task_sentiment","text":"Predefined task sentiment analysis","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predefined task for sentiment analysis — task_sentiment","text":"","code":"task_sentiment()"},{"path":"https://seraphinem.github.io/quallmer/reference/task_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predefined task for sentiment analysis — task_sentiment","text":"task object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_stance.html","id":null,"dir":"Reference","previous_headings":"","what":"Predefined task for stance detection (position taking) — task_stance","title":"Predefined task for stance detection (position taking) — task_stance","text":"Predefined task stance detection (position taking)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_stance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predefined task for stance detection (position taking) — task_stance","text":"","code":"task_stance(topic = \"the given topic\")"},{"path":"https://seraphinem.github.io/quallmer/reference/task_stance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predefined task for stance detection (position taking) — task_stance","text":"topic character string specifying topic stance detection.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task_stance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predefined task for stance detection (position taking) — task_stance","text":"task object","code":""}]
