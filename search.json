[{"path":[]},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"project-structure--modules","dir":"","previous_headings":"","what":"Project Structure & Modules","title":"Repository Guidelines","text":"R: Package code Shiny app (e.g., annotate(), validate_app()). tests/testthat: Unit tests (testthat 3e) test runner tests/testthat.R. man: Generated Rd docs (roxygen2); edit hand. vignettes: Long-form docs built knitr/rmarkdown. data, data_creation: Example datasets scripts used create . pkgdown, _pkgdown.yml, docs: Website configuration built site. DESCRIPTION, NAMESPACE: Package metadata; NAMESPACE roxygen2-generated. .github/workflows: CI R CMD check, coverage, pkgdown.","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"build-test-and-develop","dir":"","previous_headings":"","what":"Build, Test, and Develop","title":"Repository Guidelines","text":"Dev loop: devtools::document(); devtools::test(); devtools::check(). Tarball/check: R CMD build . R CMD check quallmer_*.tar.gz ---cran. Site: pkgdown::build_site() updates docs/. App: quallmer::validate_app() launches validator UI.","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"coding-style--naming","dir":"","previous_headings":"","what":"Coding Style & Naming","title":"Repository Guidelines","text":"Indentation: 2 spaces; avoid tabs overly long lines. Naming: snake_case functions/objects (e.g., trail_settings, task_sentiment). Roxygen2: Use complete param/return docs @export user-facing APIs. Imports: Prefer namespace-qualified calls (e.g., dplyr::mutate).","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"ellmer-aligned-conventions","dir":"","previous_headings":"","what":"ellmer-Aligned Conventions","title":"Repository Guidelines","text":"R sessions: run R --quiet --vanilla reproducibility. Tests: map R/{name}.R tests/testthat/test-{name}.R; use devtools::test(reporter = \"check\"); avoid devtools::test_active_file(). Docs: sentence case headings; run devtools::document() changes; ensure topics appear _pkgdown.yml pass pkgdown::check_pkgdown(). Structure: lead high-level logic; keep helpers ; avoid nested functions unless trivial. Errors: prefer cli::cli_abort() tidyverse error style. Example: see input validation R/annotate.R.","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"Repository Guidelines","text":"Framework: testthat (edition 3). Place files tests/testthat/test-*.R. Write small, focused tests; mock external services. network unit tests. Run locally devtools::test(); coverage covr::package_coverage(). CI: GitHub Actions run R CMD check, snapshots, Codecov upload.","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"commit--pull-requests","dir":"","previous_headings":"","what":"Commit & Pull Requests","title":"Repository Guidelines","text":"Commits: Concise, imperative subject (e.g., “add trail comparison summary”). Reference issues/PRs applicable (e.g., Fixes #21). PRs: Include clear summary, motivation, scope; link issues; add tests new behavior; update docs/vignettes needed; include screenshots/GIFs UI changes validate_app(). NEWS: Add succinct bullet NEWS.md user-facing change. Template: Use .github/pull_request_template.md structure submissions.","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"news-entries-tidyverse-style","dir":"","previous_headings":"Commit & Pull Requests","what":"NEWS Entries (tidyverse style)","title":"Repository Guidelines","text":"Prefer one bullet per change; keep user-facing concise. Use code font functions/args; reference issues/PRs authors. annotate() now accepts named vectors IDs output (#123, @login). Fixed crash validate_app() gold column missing (#145). Documentation: Added “Agreement metrics” vignette; clarified task() examples (#150).","code":""},{"path":"https://seraphinem.github.io/quallmer/AGENTS.html","id":"security--configuration","dir":"","previous_headings":"","what":"Security & Configuration","title":"Repository Guidelines","text":"Secrets: Never commit API keys. Locally, set OPENAI_API_KEY environment. CI uses repository secrets pkgdown builds. Reproducibility: Prefer pinned package versions reporting issues; include sessionInfo() bug reports.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"project-overview","dir":"","previous_headings":"","what":"Project Overview","title":"Claude Code Guidelines for quallmer","text":"quallmer R package qualitative data annotation validation. provides: - annotate(): Core function LLM-powered text annotation - validate_app(): Shiny application validating annotations gold standards - Integration ellmer framework LLM interactions","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"key-development-commands","dir":"","previous_headings":"","what":"Key Development Commands","title":"Claude Code Guidelines for quallmer","text":"General Advice: - Run R R --quiet --vanilla clean, reproducible sessions - Always run devtools::document() modifying roxygen2 comments - new code requires accompanying tests","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"testing","dir":"","previous_headings":"Key Development Commands","what":"Testing","title":"Claude Code Guidelines for quallmer","text":"Test files follow pattern: tests/testthat/test-{name}.R maps R/{name}.R Run tests: devtools::test(reporter = \"check\") Run specific tests: devtools::test(filter = \"name\", reporter = \"check\") Avoid devtools::test_active_file() - prefer full test suite Place new tests near similar existing tests Check coverage: covr::package_coverage()","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"documentation","dir":"","previous_headings":"Key Development Commands","what":"Documentation","title":"Claude Code Guidelines for quallmer","text":"Run devtools::document() modifying roxygen2 comments Every user-facing function needs @export complete roxygen2 documentation Add new documentation topics _pkgdown.yml Verify pkgdown::check_pkgdown() Use sentence case headings documentation Update NEWS.md user-facing changes following tidyverse style","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"building-and-checking","dir":"","previous_headings":"Key Development Commands","what":"Building and Checking","title":"Claude Code Guidelines for quallmer","text":"","code":"# Build tarball R CMD build .  # Check as CRAN R CMD check quallmer_*.tar.gz --as-cran"},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"website","dir":"","previous_headings":"Key Development Commands","what":"Website","title":"Claude Code Guidelines for quallmer","text":"","code":"pkgdown::build_site()     # Build/update website in docs/ pkgdown::check_pkgdown()  # Validate pkgdown configuration"},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"running-the-shiny-app","dir":"","previous_headings":"Key Development Commands","what":"Running the Shiny App","title":"Claude Code Guidelines for quallmer","text":"","code":"quallmer::validate_app()  # Launch validation interface"},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"project-structure--modules","dir":"","previous_headings":"","what":"Project Structure & Modules","title":"Claude Code Guidelines for quallmer","text":"R/: Package source code (e.g., annotate.R, validate_app.R, task_*.R) tests/testthat/: Unit tests using testthat edition 3 tests/testthat.R: Test runner man/: Auto-generated documentation via roxygen2 (edit manually) vignettes/: Package vignettes long-form documentation data/: Example datasets (e.g., baker, druguse) data_creation/: Scripts generating package datasets **_pkgdown.yml, docs/**: pkgdown website configuration built site DESCRIPTION: Package metadata dependencies NAMESPACE: Auto-generated roxygen2 .github/workflows/: GitHub Actions CI/CD","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"code-style","dir":"","previous_headings":"Coding Conventions","what":"Code Style","title":"Claude Code Guidelines for quallmer","text":"Indentation: 2 spaces (tabs) Line length: Keep reasonable; avoid overly long lines Examples: trail_settings(), task_sentiment(), gold_standard Organization: Newspaper-style - high-level functions first, helpers Nested functions: Avoid nested function definitions (except trivial lambdas) Imports: Use namespace-qualified calls: dplyr::mutate(), cli::cli_abort() File endings: Ensure source files end trailing newline","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"error-messages","dir":"","previous_headings":"Coding Conventions","what":"Error Messages","title":"Claude Code Guidelines for quallmer","text":"Use cli::cli_abort() user-facing errors (never stop()) Clear, actionable messages tell users went wrong fix Use {variable} interpolation values Bullet points (*, , x) structured messages See R/annotate.R input validation examples","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"documentation-1","dir":"","previous_headings":"Coding Conventions","what":"Documentation","title":"Claude Code Guidelines for quallmer","text":"Use roxygen2 exported functions Include complete @param @return documentation Add @export user-facing APIs Add @examples appropriate (use \\dontrun{} examples requiring API keys) Document user-facing functions, even internal helpers users might see","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"ellmer-integration","dir":"","previous_headings":"","what":"ellmer Integration","title":"Claude Code Guidelines for quallmer","text":"quallmer builds ellmer framework. Key points: - Use ellmer’s chat() turn() LLM interactions - Follow ellmer conventions model configuration API usage - Maintain compatibility ellmer’s streaming async features","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"framework-and-workflow","dir":"","previous_headings":"Testing Guidelines","what":"Framework and Workflow","title":"Claude Code Guidelines for quallmer","text":"testthat edition 3 File naming: tests/testthat/test-{name}.R maps R/{name}.R new code requires accompanying tests Place new tests near similar existing tests","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"running-tests","dir":"","previous_headings":"Testing Guidelines","what":"Running Tests","title":"Claude Code Guidelines for quallmer","text":"Run tests: devtools::test(reporter = \"check\") Run specific tests: devtools::test(filter = \"name\", reporter = \"check\") Avoid devtools::test_active_file() - always run full test suite Check coverage: covr::package_coverage()","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"testing-principles","dir":"","previous_headings":"Testing Guidelines","what":"Testing Principles","title":"Claude Code Guidelines for quallmer","text":"Write focused, atomic tests function Mock external services (LLM APIs) - network calls unit tests Use test fixtures tests/testthat/fixtures/ needed Test edge cases, error conditions, typical usage patterns Tests fast deterministic","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"cicd","dir":"","previous_headings":"Testing Guidelines","what":"CI/CD","title":"Claude Code Guidelines for quallmer","text":"GitHub Actions run R CMD check multiple platforms (Linux, macOS, Windows) Code coverage tracked reported via Codecov pkgdown site built deployed automatically push main","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"commits","dir":"","previous_headings":"Git Workflow","what":"Commits","title":"Claude Code Guidelines for quallmer","text":"Use imperative mood: “Add feature” “Added feature” Keep subject line concise (50 chars less) Reference issues applicable: “Fixes #21”, “Closes #45” Include Claude Code attribution appropriate:","code":"Add trail comparison summary  Generated with Claude Code  Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"pull-requests","dir":"","previous_headings":"Git Workflow","what":"Pull Requests","title":"Claude Code Guidelines for quallmer","text":"Use .github/pull_request_template.md structure PRs. Include: - Clear summary: PR ? - Motivation: change needed? - Scope: files/functions affected? - Tests: Add tests new behavior - Documentation: Update man pages, vignettes, README needed - NEWS: Add bullet NEWS.md user-facing changes - Screenshots: UI changes validate_app(), include /screenshots","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"newsmd-entries","dir":"","previous_headings":"Git Workflow","what":"NEWS.md Entries","title":"Claude Code Guidelines for quallmer","text":"Follow tidyverse style: - One bullet per user-facing change - Use code font functions: `annotate()` - Reference issues/PRs contributors: (#123, @username) - Examples: - `annotate()` now supports custom system prompts (#45). - Fixed error `validate_app()` gold column missing (#67). - Documentation: Added \"Custom tasks\" vignette (#78).","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"important-files-to-know","dir":"","previous_headings":"File Locations","what":"Important Files to Know","title":"Claude Code Guidelines for quallmer","text":"R/annotate.R: Main annotation function R/validate_app.R: Shiny validation app R/task_*.R: Task definition functions (sentiment, summary, etc.) R/utils.R: Utility functions tests/testthat/test-annotate.R: Tests annotation tests/testthat/test-validate_app.R: Tests Shiny app vignettes/quallmer.Rmd: Main package vignette","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"configuration-files","dir":"","previous_headings":"File Locations","what":"Configuration Files","title":"Claude Code Guidelines for quallmer","text":".Rbuildignore: Files/patterns exclude R CMD build _pkgdown.yml: Website structure appearance .github/workflows/: CI configuration","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"api-keys","dir":"","previous_headings":"Security & Best Practices","what":"API Keys","title":"Claude Code Guidelines for quallmer","text":"Never commit API keys tokens Use environment variables: OPENAI_API_KEY, ANTHROPIC_API_KEY Document API key setup vignettes/README CI uses repository secrets automated builds","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"reproducibility","dir":"","previous_headings":"Security & Best Practices","what":"Reproducibility","title":"Claude Code Guidelines for quallmer","text":"Use R --quiet --vanilla clean R sessions Include sessionInfo() reporting issues Pin package versions needed reproducibility","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"adding-a-new-task-type","dir":"","previous_headings":"Common Tasks","what":"Adding a New Task Type","title":"Claude Code Guidelines for quallmer","text":"Create R/task_newtype.R roxygen docs Add tests/testthat/test-task_newtype.R Document appropriate vignette Update _pkgdown.yml reference section Add NEWS.md entry Run devtools::document() devtools::check()","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"updating-the-shiny-app","dir":"","previous_headings":"Common Tasks","what":"Updating the Shiny App","title":"Claude Code Guidelines for quallmer","text":"Modify R/validate_app.R Test interactively quallmer::validate_app() Add tests tests/testthat/test-validate_app.R Take /screenshots PR Document UI changes NEWS.md","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"fixing-a-bug","dir":"","previous_headings":"Common Tasks","what":"Fixing a Bug","title":"Claude Code Guidelines for quallmer","text":"Write failing test reproduces bug Fix bug source code Verify test now passes Add NEWS.md entry issue reference Create PR linking issue","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"Claude Code Guidelines for quallmer","text":"R Packages (2e): Comprehensive guide R package development tidyverse style guide: Coding style conventions testthat documentation: Testing framework pkgdown documentation: Website generation ellmer documentation: LLM integration framework quallmer documentation","code":""},{"path":"https://seraphinem.github.io/quallmer/CLAUDE.html","id":"general-attitude","dir":"","previous_headings":"","what":"General attitude","title":"Claude Code Guidelines for quallmer","text":"suggest change, think critically, don’t just tell great brilliant improvement start trying implement . suggestions great.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/getting-started.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic usage","title":"Getting started with quallmer","text":"quallmer package developed using R. Please make sure recent version R RStudio installed computer. new R RStudio, can find great free--charge 1.5h introduction R RStudio instats. get started quallmer, first need install package GitHub. , can load package begin using functions.","code":"# If you don't have pak installed yet, uncomment and run the following line: # install.packages(\"pak\") # Then, install quallmer using pak: pak::pak(\"SeraphineM/quallmer\") library(quallmer) #> Loading required package: ellmer"},{"path":"https://seraphinem.github.io/quallmer/articles/getting-started.html","id":"overview-of-tutorials","dir":"Articles","previous_headings":"","what":"Overview of tutorials","title":"Getting started with quallmer","text":"using large language models, users need sign API key LLM provider, OpenAI, download open-source model like Ollama. quallmer package supports multiple LLM providers ellmer package, allowing users choose one best fits needs. Using qlm_code(), users can generate structured, interpretable outputs powered large language models (LLMs). package allows users create custom codebooks tailored specific research questions data types using qlm_codebook(). package also includes library example codebooks illustrating common qualitative coding workflows, sentiment analysis, thematic coding, stance detection. package provides functions validating comparing coded results: qlm_compare() compares multiple coded results assess inter-rater reliability qlm_validate() validates coded results gold standard (human-coded reference data) qlm_replicate() re-executes coding different settings test reliability tutorials guide following topics: Signing OpenAI API key: tutorial guide process obtaining API key OpenAI, necessary using OpenAI’s LLMs quallmer package. Working open-source Ollama model: tutorial demonstrate use quallmer package open-source Ollama model qualitative coding tasks. Creating codebooks: tutorial walk process defining custom codebooks using qlm_codebook() function, allowing tailor LLM’s output specific research needs. Comparing replicating coded results: tutorial guide process using qlm_compare() function assess inter-rater reliability multiple coded results generated different models coding runs assess accuracy precision human-coded gold standard using qlm_validate(). also cover use qlm_replicate() function re-execute coding different settings reliability testing. quallmer trail traceability: tutorial introduce quallmer trail system, automatically captures provenance metadata full workflow traceability using qlm_trail() related functions. Using Validate App: tutorial introduce Validate App (provided quallmer.app package), allows manually code data, check LLM annotations, calculate inter-rater reliability user-friendly intuitive interface. hope tutorials help get started quallmer package empower leverage large language models qualitative research projects!","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Loading packages and data","title":"Example: Sentiment analysis","text":"","code":"library(quanteda.tidy) ## Loading required package: quanteda ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. ##  ## Attaching package: 'quanteda.tidy' ## The following object is masked from 'package:stats': ##  ##     filter library(dplyr) ##  ## Attaching package: 'dplyr' ## The following object is masked from 'package:quanteda.tidy': ##  ##     add_tally ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(tidyr) library(quallmer) ## Loading required package: ellmer # inspect the labelled data convert(data_corpus_LMRDsample) %>%   count(polarity, rating) %>%   pivot_wider(names_from = polarity, values_from = n, values_fill = 0) %>%   janitor::adorn_totals(\"row\") ##  rating neg pos ##       1  43   0 ##       2  18   0 ##       3  20   0 ##       4  19   0 ##       7   0  22 ##       8   0  20 ##       9   0  22 ##      10   0  36 ##   Total 100 100"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"inspecting-the-codebook","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Inspecting the codebook","title":"Example: Sentiment analysis","text":"data_codebook_sentiment codebook provides structured sentiment analysis. Let’s examine components: codebook produces two outputs: - polarity: Categorical sentiment (negative positive) - rating: Numeric sentiment rating 1 (negative) 10 (positive)","code":"# View the codebook name and role cat(\"Codebook name:\", data_codebook_sentiment$name, \"\\n\\n\") ## Codebook name: Sentiment analysis cat(\"Role:\", data_codebook_sentiment$role, \"\\n\\n\") ## Role: You are a political communication analyst evaluating public statements. # View the instructions cat(\"Instructions:\\n\", data_codebook_sentiment$instructions, \"\\n\\n\") ## Instructions: ##  Analyze the sentiment of this text, on both a 1-10 scale and as a polarity of negative or positive. # View the schema structure cat(\"Schema:\\n\") ## Schema: print(data_codebook_sentiment$schema) ## <ellmer::TypeObject> ##  @ description          : NULL ##  @ required             : logi TRUE ##  @ properties           :List of 2 ##  .. $ sentiment: <ellmer::TypeEnum> ##  ..  ..@ description: chr \"Overall sentiment polarity: negative (neg) or positive (pos)\" ##  ..  ..@ required   : logi TRUE ##  ..  ..@ values     : chr [1:2] \"neg\" \"pos\" ##  .. $ rating   : <ellmer::TypeBasic> ##  ..  ..@ description: chr \"Sentiment rating from 1 (most negative) to 10 (most positive)\" ##  ..  ..@ required   : logi TRUE ##  ..  ..@ type       : chr \"integer\" ##  @ additional_properties: logi FALSE"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"coding-movie-reviews-using-gemini-2-5-flash","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Coding movie reviews using Gemini 2.5 Flash","title":"Example: Sentiment analysis","text":"Total cost:","code":"# Apply sentiment analysis using qlm_code() coded_g2.5_flash <- qlm_code(   data_corpus_LMRDsample,   codebook = data_codebook_sentiment,   model = \"google_gemini/gemini-2.5-flash\",   max_active = 20,   include_cost = TRUE,   params = params(temperature = 0) ) cat(\"Total cost: $\", round(sum(coded_g2.5_flash$cost), 4), sep = \"\") ## Total cost: $0.2478"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"validating-against-gold-standard","dir":"Articles > Pkgdown > Examples","previous_headings":"","what":"Validating against gold standard","title":"Example: Sentiment analysis","text":"corpus includes human-coded sentiment labels docvars. can use qlm_validate() assess LLM’s performance: treat rating variable interval, get validation metrics:","code":"# Extract gold standard labels from corpus docvars # The docvars include both 'polarity' (neg/pos) and 'rating' (1-10) gold_standard <- data_corpus_LMRDsample |>   mutate(.id = docnames(data_corpus_LMRDsample)) |>   docvars()  # Validate polarity predictions (nominal data) polarity_validation <- qlm_validate(   coded_g2.5_flash,   gold = gold_standard,   by = \"polarity\",   level = \"nominal\" ) print(polarity_validation) ## # quallmer validation ## # n: 200 | classes: 2 | average: macro ##  ## accuracy:      0.9500 ## precision:     0.9500 ## recall:        0.9500 ## f1:            0.9500 ## Cohen's kappa: 0.9000 ## Pearson's r:   0.9500 # Validate rating predictions (ordinal data) rating_validation <- qlm_validate(   coded_g2.5_flash,   gold = gold_standard,   by = \"rating\",   level = \"ordinal\" ) print(rating_validation) ## # quallmer validation ## # n: 200 | levels: 10 ##  ## Spearman's rho:0.5570 ## Kendall's tau: 0.4851 ## Pearson's r:   0.5570 ## MAE:           1.8000 qlm_validate(   coded_g2.5_flash,   gold = gold_standard,   by = \"rating\",   level = \"interval\" ) ## # quallmer validation ## # n: 200 ##  ## Pearson's r:   0.9368 ## ICC:           0.9350 ## MAE:           0.7600 ## RMSE:          1.2845"},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"compared-to-the-previous-llm-scoring","dir":"Articles > Pkgdown > Examples","previous_headings":"Comparing to a second LLM coding from GPT-5.1","what":"Compared to the previous LLM scoring","title":"Example: Sentiment analysis","text":"can use qlm_compare() try advanced model, see changes things, comparing performance previous model, also gold standard. Now can compare agreement two LLM codings, polarity: numerical (1-10) variable rating, can specify level ordinal: change tolerance agreement, see agreement changes measures : treat 1-10 ratings interval, see:","code":"# Apply sentiment analysis using qlm_code() coded_gpt5.1 <- qlm_code(   data_corpus_LMRDsample,   codebook = data_codebook_sentiment,   model = \"openai/gpt-5.1\",   max_active = 10,   include_cost = TRUE,   params = params(temperature = 0) ) qlm_compare(coded_g2.5_flash, coded_gpt5.1, by = \"polarity\", level = \"nominal\") ## # Inter-rater reliability ## # Subjects: 200  ## # Raters:   2  ## # Level:    nominal  ##  ## Krippendorff's alpha: 0.9501 ## Cohen's kappa:        0.9500 ## Percent agreement:    0.9750 qlm_compare(coded_g2.5_flash, coded_gpt5.1, by = \"rating\", level = \"ordinal\") ## # Inter-rater reliability ## # Subjects: 200  ## # Raters:   2  ## # Level:    ordinal  ##  ## Krippendorff's alpha: 0.9443 ## Weighted kappa:       0.7525 ## Kendall's W:          0.9538 ## Spearman's rho:       0.9609 ## Percent agreement:    0.5900 qlm_compare(coded_g2.5_flash, coded_gpt5.1, by = \"rating\", level = \"ordinal\",             tolerance = 1) ## # Inter-rater reliability ## # Subjects: 200  ## # Raters:   2  ## # Level:    ordinal  ##  ## Krippendorff's alpha: 0.9443 ## Weighted kappa:       0.7525 ## Kendall's W:          0.9538 ## Spearman's rho:       0.9609 ## Percent agreement:    0.9700 qlm_compare(coded_g2.5_flash, coded_gpt5.1, by = \"rating\", level = \"interval\") ## # Inter-rater reliability ## # Subjects: 200  ## # Raters:   2  ## # Level:    interval  ##  ## Krippendorff's alpha: 0.9743 ## ICC:                  0.9744 ## Pearson's r:          0.9793 ## Percent agreement:    0.5900"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/examples/example_sentiment.html","id":"gpt-5-1-versus-the-gold-standard","dir":"Articles > Pkgdown > Examples","previous_headings":"Comparing to a second LLM coding from GPT-5.1","what":"GPT-5.1 versus the “gold standard”","title":"Example: Sentiment analysis","text":"Finally, can compare new LLM scoring gold standard, polarity: Compare previous values Gemini 2.5 Flash: ’s tiny improvement. interval rating: Compared Gemini 2.5 Flash: Call draw!","code":"qlm_validate(   coded_gpt5.1,   gold = gold_standard,   by = \"polarity\",   level = \"nominal\" ) ## # quallmer validation ## # n: 200 | classes: 2 | average: macro ##  ## accuracy:      0.9550 ## precision:     0.9561 ## recall:        0.9550 ## f1:            0.9550 ## Cohen's kappa: 0.9100 ## Pearson's r:   0.9550 ## # quallmer validation ## # n: 200 | classes: 2 | average: macro ##  ## accuracy:      0.9500 ## precision:     0.9500 ## recall:        0.9500 ## f1:            0.9500 ## Cohen's kappa: 0.9000 ## Pearson's r:   0.9500 qlm_validate(   coded_gpt5.1,   gold = gold_standard,   by = \"rating\",   level = \"interval\" ) ## # quallmer validation ## # n: 200 ##  ## Pearson's r:   0.9355 ## ICC:           0.9346 ## MAE:           0.7600 ## RMSE:          1.2329 ## # quallmer validation ## # n: 200 ##  ## Pearson's r:   0.9368 ## ICC:           0.9350 ## MAE:           0.7600 ## RMSE:          1.2845"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Loading packages and data","title":"Comparing and replicating coded results","text":"","code":"# We will use the quanteda package # for loading a sample corpus of inaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes, # we will use a subset of the inaugural speeches corpus # The ten most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[50:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"using-a-codebook-for-this-tutorial","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Using a codebook for this tutorial","title":"Comparing and replicating coded results","text":"tutorial, ’ll use built-data_codebook_fact quick example. allows us focus comparison validation functions rather codebook design. Note: built-codebooks provided examples starting points. actual research projects, create custom codebooks specific research questions (see “Creating codebooks” tutorial details).","code":"# View the built-in sentiment codebook data_codebook_ideology ## quallmer codebook: Ideological scaling  ##   Input type:   text ##   Role:         You are an expert political scientist specializing in ideolo... ##   Instructions: Rate the ideological position of this text on a scale from 0... ##   Output schema:ellmer::TypeObject"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"initial-coding-run","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Initial coding run","title":"Comparing and replicating coded results","text":"Let’s code speeches using codebook specific model settings:","code":"# Code the speeches with GPT-4o using the built-in codebook on ideology coded1 <- qlm_code(data_corpus_inaugural,                    codebook = data_codebook_ideology,                    model = \"openai/gpt-4o\",                    params = params(temperature = 0),                    name = \"gpt4o_run\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 1 -> 10 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■      91% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # View the results coded1 ## # quallmer coded object ## # Run:      gpt4o_run ## # Codebook: Ideological scaling ## # Model:    openai/gpt-4o ## # Units:    11 ##  ## # A tibble: 11 × 3 ##    .id          score explanation                                                ##  * <chr>        <int> <chr>                                                      ##  1 1985-Reagan      8 The text emphasizes reducing government size, cutting tax… ##  2 1989-Bush        7 The text emphasizes free markets, limited government inte… ##  3 1993-Clinton     4 The text emphasizes themes of renewal, change, and respon… ##  4 1997-Clinton     4 The text emphasizes themes of equality, community, and op… ##  5 2001-Bush        6 The text emphasizes traditional American values such as f… ##  6 2005-Bush        7 The text emphasizes a strong commitment to spreading demo… ##  7 2009-Obama       3 The text emphasizes themes of unity, collective responsib… ##  8 2013-Obama       3 The text emphasizes equality, collective action, and soci… ##  9 2017-Trump       8 The text emphasizes nationalism, protectionism, and a foc… ## 10 2021-Biden       3 The text emphasizes unity, democracy, and addressing soci… ## 11 2025-Trump       8 The text emphasizes nationalism, strong border control, m…"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"replicating-with-different-settings","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Replicating with different settings","title":"Comparing and replicating coded results","text":"qlm_replicate() function allows re-execute coding different models, parameters, codebooks maintaining provenance chain. useful testing sensitivity results different settings.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"replicating-with-a-different-model","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Replicating with different settings","what":"Replicating with a different model","title":"Comparing and replicating coded results","text":"","code":"# Replicate the coding with openai/gpt-4o-mini coded2 <- qlm_replicate(coded1,                         model = \"openai/gpt-4o-mini\",                         name = \"mini_run\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"replicating-with-different-temperature","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Replicating with different settings","what":"Replicating with different temperature","title":"Comparing and replicating coded results","text":"","code":"# Replicate with higher temperature for more variability coded3 <- qlm_replicate(coded1,                         params = params(temperature = 0.7),                         name = \"gpt4o_temp07\") ## [working] (0 + 0) -> 2 -> 9 | ■■■■■■■■■■■■■■■■■■■■■■■■■■        82% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100%"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"comparing-multiple-coded-results","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Comparing multiple coded results","title":"Comparing and replicating coded results","text":"multiple coded results, can assess inter-rater reliability using qlm_compare(). useful want check consistency across different models, coders, coding runs.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"computing-krippendorffs-alpha","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Comparing multiple coded results","what":"Computing Krippendorff’s alpha","title":"Comparing and replicating coded results","text":"output shows: reliability measures values, appropriate ordinal data. number subjects (11 speeches) raters (3 LLM coding runs). level measurement (interval).","code":"# Compare the first three runs to assess reliability comparison <- qlm_compare(coded1, coded2, coded3,                            by = \"score\",                           level = \"ordinal\")  # View the comparison results comparison ## # Inter-rater reliability ## # Subjects: 11  ## # Raters:   3  ## # Level:    ordinal  ##  ## Krippendorff's alpha: 0.9213 ## Kendall's W:          0.9283 ## Spearman's rho:       0.9519 ## Percent agreement:    0.4545"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"computing-percent-agreement-with-a-tolerance","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Comparing multiple coded results","what":"Computing percent agreement with a tolerance","title":"Comparing and replicating coded results","text":"treat data ordinal, relax “tolerance” agreement +/-1 values compared, can get different definition agreement, thus changing score. “Percent agreement” rises substantially.","code":"qlm_compare(coded1, coded2, coded3,              by = \"score\",             level = \"ordinal\",             tolerance = 1) ## # Inter-rater reliability ## # Subjects: 11  ## # Raters:   3  ## # Level:    ordinal  ##  ## Krippendorff's alpha: 0.9213 ## Kendall's W:          0.9283 ## Spearman's rho:       0.9519 ## Percent agreement:    0.9091"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"validating-against-a-gold-standard","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Validating against a gold standard","title":"Comparing and replicating coded results","text":"human-coded reference data (gold standard), can assess accuracy LLM coding using qlm_validate(). computes classification metrics like accuracy, precision, recall, F1-score.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"creating-a-gold-standard","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Validating against a gold standard","what":"Creating a gold standard","title":"Comparing and replicating coded results","text":"example, let’s simulate human-coded sentiment data:","code":"# In practice, this would be your human-coded reference data gold_standard <- data.frame(   .id = coded1$.id,   score = c(8, 7, 4, 7, 6, 7, 5, 6, 8, 3, 8) )"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"computing-validation-metrics","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Validating against a gold standard","what":"Computing validation metrics","title":"Comparing and replicating coded results","text":"output shows: Overall accuracy: proportion correct classifications Precision: proportion positive identifications actually correct Recall: proportion actual positives identified correctly F1-score: harmonic mean precision recall Cohen’s kappa: agreement adjusted chance course, can also perform validation treating data ordinal even interval:","code":"# Validate the LLM coding against the gold standard validation <- qlm_validate(coded1,                            gold = gold_standard,                            by = \"score\") ## Warning: While computing multiclass `precision()`, some levels had no predicted events ## (i.e. `true_positive + false_positive = 0`). ## Precision is undefined in this case, and those levels will be removed from the ## averaged result. ## Note that the following number of true events actually occurred for each ## problematic event level: ## '5': 1 ## While computing multiclass `precision()`, some levels had no predicted events ## (i.e. `true_positive + false_positive = 0`). ## Precision is undefined in this case, and those levels will be removed from the ## averaged result. ## Note that the following number of true events actually occurred for each ## problematic event level: ## '5': 1 # View validation results validation ## # quallmer validation ## # n: 11 | classes: 6 | average: macro ##  ## accuracy:      0.7273 ## precision:     0.7667 ## recall:        0.6944 ## f1:            0.7267 ## Cohen's kappa: 0.6667 ## Pearson's r:   0.6944 qlm_validate(coded1, gold = gold_standard, by = \"score\", level = \"ordinal\") ## # quallmer validation ## # n: 11 | levels: 6 ##  ## Spearman's rho:0.8884 ## Kendall's tau: 0.8000 ## Pearson's r:   0.8884 ## MAE:           0.7273 qlm_validate(coded1, gold = gold_standard, by = \"score\", level = \"interval\") ## # quallmer validation ## # n: 11 ##  ## Pearson's r:   0.8092 ## ICC:           0.7460 ## MAE:           0.7273 ## RMSE:          1.4142"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"best-practices-for-reliability-and-validation","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Best practices for reliability and validation","title":"Comparing and replicating coded results","text":"Multiple replications: Run coding least 2-3 different models settings assess consistency Consistent temperature: Use temperature = 0 deterministic reliable results Document settings: Use name parameter track different runs Gold standard size: Aim least 100 examples gold standard reliable validation metrics Use Krippendorff’s alpha nominal/ordinal data Use Cohen’s/Fleiss’ kappa categorical agreement Use correlation measures continuous data α κ > 0.80: Almost perfect agreement α κ > 0.60: Substantial agreement α κ > 0.40: Moderate agreement α κ < 0.40: Fair poor agreement","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/compare.html","id":"summary","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Summary","title":"Comparing and replicating coded results","text":"tutorial, learned : Use qlm_replicate() systematically test coding across different models settings Use qlm_compare() assess inter-rater reliability multiple coded results Use qlm_validate() measure accuracy gold standard Interpret reliability validation metrics tools help ensure qualitative coding robust, reproducible, scientifically sound.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Loading packages and data","title":"Creating codebooks","text":"","code":"# We will use the quanteda package  # for loading a sample corpus of innaugural speeches # If you have not yet installed the quanteda package, you can do so by: # install.packages(\"quanteda\") library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes,  # we will use a subset of the inaugural speeches corpus # The ten most recent speeches in the corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[50:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"learning-from-built-in-codebooks-examples","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Learning from built-in codebooks examples","title":"Creating codebooks","text":"creating custom codebook, let’s inspect built-data_codebook_sentiment understand structure: shows us: - input type text - role defines model political communication analyst - instructions guide model analyze sentiment 1-10 scale classify polarity - schema specifies expected output structure fields polarity rating Now let’s create custom codebook specific research question.","code":"# View the codebook data_codebook_sentiment ## quallmer codebook: Sentiment analysis  ##   Input type:   text ##   Role:         You are a political communication analyst evaluating public ... ##   Instructions: Analyze the sentiment of this text, on both a 1-10 scale and... ##   Output schema:ellmer::TypeObject # Inspect the role data_codebook_sentiment$role ## [1] \"You are a political communication analyst evaluating public statements.\" # Inspect the instructions data_codebook_sentiment$instructions ## [1] \"Analyze the sentiment of this text, on both a 1-10 scale and as a polarity of negative or positive.\""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"defining-custom-instructions","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Defining custom instructions","title":"Creating codebooks","text":"Defining instructions crucial step creating custom codebooks. instructions guide LLM interpret input data kind output generate. example, create instructions tell LLM score documents based alignment political left ideologies. Instructions can much longer complex depending task hand. Instructions clear specific ensure LLM understands task requirements.","code":"instructions <- \"Score the following document on a scale of how much it aligns with the political left. The political left is defined as groups which advocate for social equality, government intervention in the economy, and progressive policies. Use the following metrics: SCORING METRIC: 3 : extremely left 2 : very left 1 : slightly left 0 : not at all left\""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"defining-the-codebook-with-qlm_codebook","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Defining the codebook with qlm_codebook()","title":"Creating codebooks","text":"qlm_codebook() function allows us specify expected structure LLM’s response. following important arguments users need specify: name: descriptive name codebook. instructions: instructions guide LLM perform coding task. schema: Defines expected structure response using ellmer’s type specifications type_object(), type_array(), etc. role: (Optional) role description model (e.g., “expert political scientist”). input_type: type input data (\"text\" \"image\"). information use ellmer’s type specifications, please refer ellmer documentation type specifications.","code":"# Define the custom codebook using qlm_codebook() ideology_codebook <- qlm_codebook(   name = \"Score Political Left Alignment\",   instructions = instructions,   schema = type_object(     score = type_number(\"Score\"),     explanation = type_string(\"Explanation\")   ),   role = \"You are an expert political scientist analyzing political texts.\",   input_type = \"text\" )"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"applying-the-custom-codebook-to-the-corpus","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Applying the custom codebook to the corpus","title":"Creating codebooks","text":"use qlm_code() function apply custom codebook sample corpus inaugural speeches. specify model use via model (case, \"openai/gpt-4o\") additional parameters needed. example, set temperature 0 deterministic outputs, improving consistency scoring across multiple runs therefore increasing reliability. qlm_code() function returns qlm_coded object, tibble containing coded results along metadata stored attributes. object prints tibble can used directly data manipulation workflows.","code":"# Apply the custom codebook to the inaugural speeches corpus coded <- qlm_code(data_corpus_inaugural,                   codebook = ideology_codebook,                   model = \"openai/gpt-4o\",                   params = params(temperature = 0)) ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # View the results coded ## # quallmer coded object ## # Run:      original ## # Codebook: Score Political Left Alignment ## # Model:    openai/gpt-4o ## # Units:    11 ##  ## # A tibble: 11 × 3 ##    .id          score explanation                                                ##  * <chr>        <dbl> <chr>                                                      ##  1 1985-Reagan      0 \"The document emphasizes reducing government intervention… ##  2 1989-Bush        0 \"The document emphasizes free markets, limited government… ##  3 1993-Clinton     1 \"The document contains elements that align slightly with … ##  4 1997-Clinton     1 \"The document contains elements that align slightly with … ##  5 2001-Bush        1 \"The document contains elements that align slightly with … ##  6 2005-Bush        0 \"The document emphasizes themes of freedom, democracy, an… ##  7 2009-Obama       2 \"The document aligns very well with the political left, e… ##  8 2013-Obama       2 \"The document aligns very well with the political left, e… ##  9 2017-Trump       0 \"The document emphasizes nationalism, protectionism, and … ## 10 2021-Biden       2 \"The document aligns very left due to its emphasis on soc… ## 11 2025-Trump       0 \"The document primarily emphasizes nationalism, sovereign…"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/custom-codebook.html","id":"summary","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Summary","title":"Creating codebooks","text":"Now successfully learned : 1. Inspect built-codebooks understand best practices 2. Create custom codebooks scratch specific research questions 3. Apply codebooks data using qlm_code() flexibility custom codebooks allows adapt quallmer qualitative coding task research!","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"precautions","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Precautions","title":"Signing up for an openai API key","text":"Closed LLMs OpenAI’s GPT-4o free use require subscription. also come ethical concerns risks, especially comes data privacy security. Therefore, always aware data use potential consequences analysis make sure enable necessary safeguards protect privacy security. addition, aware license use OpenAI models comes along adhering specific regulations avoid misuse. Therefore, always aware data use potential consequences analysis make sure enable necessary safeguards protect privacy security.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"setting-up-an-api-key-for-openai-models","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Setting up an API key for openai models","title":"Signing up for an openai API key","text":"openai API provides access various called closed models (fee-based, open-source). services available (example, Claude Google Gemini, etc.) require slightly different set-ups. can find information pricing openai .","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"to-use-the-openai-api-please-follow-these-steps","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Setting up an API key for openai models","what":"To use the openai API, please follow these steps:","title":"Signing up for an openai API key","text":"Go openai playground: https://platform.openai.com/playground> Click Sign top right corner Fill details confirm Sign Click now Settings icon top right corner Go Billing provide billing information (otherwise won’t work!) billing information complete, can create new project (top left corner, click Default Project) Click Dashboard top right corner Click API keys left side panel bottom Click Create new secret key Copy key close window copied key, save somewhere safe accessible. security reasons, won’t able view openai account. lose , need regenerate . Keep API key safe share others. suspect key compromised, can regenerate dashboard. aware charged usage API via key.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html","id":"configuring-your-openai-api-key-in-rstudio","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Setting up an API key for openai models","what":"Configuring your openai API key in RStudio","title":"Signing up for an openai API key","text":"interact openai API, ’s required valid OPENAI_API_KEY environment variable R. can establish environment variable globally including -called .Renviron file. approach ensures environment variable persists across R sessions Shiny app runs background. set commands open .Renviron file modification: Add following line .Renviron, replacing “APIKEY” actual API key: OPENAI_API_KEY=“APIKEY”. need restart R session changes take effect. can clicking Session menu RStudio selecting Restart R. Caution: ’re using version control systems like GitHub GitLab, remember include .Renviron .gitignore file prevent exposing API key! maintain privacy data using gptstudio, highlight, include prompt, otherwise upload sensitive data, code, text remain confidential. Now ready use openai models quallmer package! example, can test setup running example sentiment analysis.","code":"require(usethis) edit_r_environ()"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"understanding-provenance-tracking","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Understanding provenance tracking","title":"The quallmer trail","text":"qlm_coded, qlm_comparison, qlm_validation objects quallmer automatically capture provenance metadata, including: Run name: unique identifier coding run Timestamp: coding executed Model: LLM model parameters used Codebook: coding instructions applied Parent runs: Links previous runs replication chain Metadata: Package versions, number units coded, etc. metadata enables full workflow traceability.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"loading-packages-and-data","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Loading packages and data","title":"The quallmer trail","text":"","code":"# We will use the quanteda package # for loading a sample corpus of inaugural speeches library(quanteda) ## Package version: 4.3.1 ## Unicode version: 15.1 ## ICU version: 74.2 ## Parallel computing: disabled ## See https://quanteda.io for tutorials and examples. library(quallmer) ## Loading required package: ellmer # For educational purposes, # we will use a subset of the inaugural speeches corpus data_corpus_inaugural <- quanteda::data_corpus_inaugural[50:60]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"creating-a-workflow-with-provenance-tracking","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Creating a workflow with provenance tracking","title":"The quallmer trail","text":"Let’s build coding workflow demonstrates trail system. ’ll use sentiment analysis example.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"initial-coding-run","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Creating a workflow with provenance tracking","what":"Initial coding run","title":"The quallmer trail","text":"","code":"# For this tutorial, we'll use the built-in sentiment codebook # For real research, you would create a custom codebook tailored to your # specific research question (see the \"Creating codebooks\" tutorial)  # Code with GPT-4o (note the 'name' parameter for tracking) coded1 <- qlm_code(data_corpus_inaugural,                    codebook = data_codebook_ideology,                    model = \"openai/gpt-4o\",                    params = params(temperature = 0),                    name = \"initial_gpt4o\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # Each qlm_coded object has a 'run' attribute with metadata attr(coded1, \"run\")$name ## [1] \"initial_gpt4o\" attr(coded1, \"run\")$metadata$timestamp ## [1] \"2026-01-04 04:58:55 UTC\""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"creating-a-replication-chain","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Creating a workflow with provenance tracking","what":"Creating a replication chain","title":"The quallmer trail","text":"use qlm_replicate(), new run automatically links parent:","code":"# Replicate with GPT-4o-mini coded2 <- qlm_replicate(coded1,                         model = \"openai/gpt-4o-mini\",                         name = \"replicate_mini\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # Check the parent relationship attr(coded2, \"run\")$parent  # Shows \"initial_gpt4o\" ## [1] \"initial_gpt4o\" # Replicate again with different temperature coded3 <- qlm_replicate(coded2,                         params = params(temperature = 0.7),                         name = \"mini_temp07\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # This creates a chain: initial_gpt4o -> replicate_mini -> mini_temp07 attr(coded3, \"run\")$parent  # Shows \"replicate_mini\" ## [1] \"replicate_mini\""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"extracting-and-displaying-provenance-trails","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Extracting and displaying provenance trails","title":"The quallmer trail","text":"qlm_trail() function extracts displays complete provenance chain quallmer objects.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"viewing-a-single-run","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Extracting and displaying provenance trails","what":"Viewing a single run","title":"The quallmer trail","text":"displays: - Run name - Parent () - Creation timestamp - Model used","code":"# Extract trail from a single object trail1 <- qlm_trail(coded1)  # Print the trail trail1 ## # quallmer trail ## Run:     initial_gpt4o ## Created: 2026-01-04 04:58:55 ## Model:   openai/gpt-4o"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"reconstructing-a-complete-chain","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Extracting and displaying provenance trails","what":"Reconstructing a complete chain","title":"The quallmer trail","text":"see full provenance chain, provide objects lineage: output shows: runs chronological order Parent-child relationships Model parameter changes across runs Timestamps step Codebook used","code":"# Provide all objects to reconstruct the complete chain full_trail <- qlm_trail(coded3, coded2, coded1)  # Print shows the complete history full_trail ## # quallmer trail (3 runs) ##  ## 1. initial_gpt4o (original) ##    2026-01-04 04:58 | openai/gpt-4o ##    Codebook: Ideological scaling ##  ## 2. replicate_mini (parent: initial_gpt4o) ##    2026-01-04 04:58 | openai/gpt-4o-mini ##    Codebook: Ideological scaling ##  ## 3. mini_temp07 (parent: replicate_mini) ##    2026-01-04 04:59 | openai/gpt-4o-mini ##    Codebook: Ideological scaling"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"assessing-robustness-of-downstream-analysis","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Assessing robustness of downstream analysis","title":"The quallmer trail","text":"qlm_trail_robustness() function helps assess whether substantive findings change across different models settings. Instead just comparing raw coded values (qlm_compare() already ), compares results downstream analysis (means, proportions, correlations, etc.).","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"defining-your-downstream-analysis","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Assessing robustness of downstream analysis","what":"Defining your downstream analysis","title":"The quallmer trail","text":"First, define function performs analysis coded data: analysis function : - Take qlm_coded object input - Return named list numeric statistics - statistic single number (e.g., mean, proportion, correlation)","code":"# Define what analysis you want to compare my_analysis <- function(coded) {   list(     mean_score = mean(coded$score, na.rm = TRUE),     sd_score = sd(coded$score, na.rm = TRUE),     n_units = sum(!is.na(coded$score))   ) }"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"computing-robustness","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Assessing robustness of downstream analysis","what":"Computing robustness","title":"The quallmer trail","text":"output shows: run: Name run statistic: analysis statistic (e.g., mean_score) value: Value run reference_value: Value reference run abs_diff: Absolute difference reference pct_diff: Percent change reference","code":"# Compute how much your analysis results differ across models robustness <- qlm_trail_robustness(coded1, coded2, coded3,                                    reference = \"initial_gpt4o\",                                    analysis_fn = my_analysis)  # View the robustness scale robustness ## # Downstream Analysis Robustness ## Reference run: initial_gpt4o ##  ##             run  statistic  value reference_value abs_diff pct_diff ##   initial_gpt4o mean_score  5.545           5.545  0.00000    0.000 ##   initial_gpt4o   sd_score  2.162           2.162  0.00000    0.000 ##   initial_gpt4o    n_units 11.000          11.000  0.00000    0.000 ##  replicate_mini mean_score  5.545           5.545  0.00000    0.000 ##  replicate_mini   sd_score  1.864           2.162  0.29812  -13.791 ##  replicate_mini    n_units 11.000          11.000  0.00000    0.000 ##     mini_temp07 mean_score  5.636           5.545  0.09091    1.639 ##     mini_temp07   sd_score  1.804           2.162  0.35761  -16.544 ##     mini_temp07    n_units 11.000          11.000  0.00000    0.000 ##  ## abs_diff: Absolute difference from reference ## pct_diff: Percent change from reference (positive = increase) ##  ## Smaller differences indicate more robust findings."},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"interpreting-robustness","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Assessing robustness of downstream analysis","what":"Interpreting robustness","title":"The quallmer trail","text":"Interpretation guidelines: <1% difference: Highly robust, findings stable 1-5% difference: Good robustness, minor variations 5-10% difference: Moderate robustness, sensitivity >10% difference: Low robustness, conclusions may change acceptable threshold depends research context magnitude effects ’re studying.","code":"# Check which statistics have large differences (>5% change) concerning <- robustness[abs(robustness$pct_diff) > 5 & !is.na(robustness$pct_diff), ]  # Check which are highly stable (<1% change) stable <- robustness[abs(robustness$pct_diff) < 1 & !is.na(robustness$pct_diff), ]"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"integrating-comparisons-and-validations","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Integrating comparisons and validations","title":"The quallmer trail","text":"trail system automatically tracks comparisons validations part workflow.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"complete-workflow-example","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Integrating comparisons and validations","what":"Complete workflow example","title":"The quallmer trail","text":"","code":"# 1. Code with two different models coded_gpt4o <- qlm_code(data_corpus_inaugural,                         codebook = data_codebook_ideology,                         model = \"openai/gpt-4o\",                         params = params(temperature = 0),                         name = \"gpt4o_run\") ## [working] (0 + 0) -> 10 -> 1 | ■■■■                               9% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% coded_mini <- qlm_replicate(coded_gpt4o,                             model = \"openai/gpt-4o-mini\",                             name = \"mini_run\") ## [working] (0 + 0) -> 9 -> 2 | ■■■■■■                            18% ## [working] (0 + 0) -> 0 -> 11 | ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■  100% # 2. Compare inter-rater reliability comparison <- qlm_compare(coded_gpt4o, coded_mini,                           by = \"score\",                           level = \"nominal\")  # View the comparison results print(comparison) ## # Inter-rater reliability ## # Subjects: 11  ## # Raters:   2  ## # Level:    nominal  ##  ## Krippendorff's alpha: 0.3538 ## Cohen's kappa:        0.3333 ## Percent agreement:    0.4545 # 3. Validate against gold standard (if you have one) # gold <- data.frame(.id = coded_gpt4o$.id, score = c(2, 3, 1, ...)) # validation <- qlm_validate(coded_gpt4o, gold = gold, by = \"score\") # print(validation)"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"viewing-complete-workflow-trail","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Integrating comparisons and validations","what":"Viewing complete workflow trail","title":"The quallmer trail","text":"","code":"# Get full provenance trail including comparisons full_trail <- qlm_trail(coded_gpt4o, coded_mini, comparison) print(full_trail) ## # quallmer trail (3 runs) ##  ## 1. gpt4o_run (original) ##    2026-01-04 04:59 | openai/gpt-4o ##    Codebook: Ideological scaling ##  ## 2. mini_run (parent: gpt4o_run) ##    2026-01-04 04:59 | openai/gpt-4o-mini ##    Codebook: Ideological scaling ##  ## 3. comparison_2b5e12c6 (parents: gpt4o_run, mini_run) ##    2026-01-04 04:59 | unknown # The trail shows parent-child relationships: # - gpt4o_run (original) # - mini_run (parent: gpt4o_run) # - comparison_... (parents: gpt4o_run, mini_run)"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"exporting-and-documenting-your-workflow","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Exporting and documenting your workflow","title":"The quallmer trail","text":"can export trail documentation reproducibility: generated report includes: Timeline coding runs Model settings parameters Comparison validation metrics (include_comparisons include_validations TRUE) System information reproducibility","code":"# Extract the full trail trail <- qlm_trail(coded_gpt4o, coded_mini, comparison)  # Save as RDS for archival # qlm_trail_save(trail, \"my_workflow_trail.rds\")  # Export as JSON for portability # qlm_trail_export(trail, \"my_workflow_trail.json\")  # Generate a human-readable report # qlm_trail_report(trail, \"my_workflow_report.qmd\")  # Include comparison metrics in the report # qlm_trail_report(trail, \"my_workflow_report.qmd\", include_comparisons = TRUE)  # Include both comparisons and validations # qlm_trail_report(trail, \"my_workflow_report.qmd\", #                  include_comparisons = TRUE, #                  include_validations = TRUE)"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html","id":"summary","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Summary","title":"The quallmer trail","text":"quallmer trail system automatically tracks coding workflow: Provenance tracking: runs timestamped model parameter information Parent-child links: qlm_replicate() maintains relationships runs Quality assessment: Use qlm_compare() check agreement qlm_trail_robustness() test conclusions change Documentation: Export trails methods sections replication packages Best practices: Name runs name parameter Use qlm_compare() assess inter-rater reliability Use qlm_trail_robustness() check findings stable across models Export trails transparency reproducibility","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"installation","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Installation","title":"Using the Validate App","text":"Validate App available companion package quallmer.app. install :","code":"# install.packages(\"pak\") pak::pak(\"SeraphineM/quallmer.app\")"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"launching-the-validate-app","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Launching the Validate App","title":"Using the Validate App","text":"launch Validate App, load quallmer.app package call validate_app() function. open Validate App new window tab web browser.","code":"library(quallmer.app) validate_app()"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"using-the-validate-app-for-manual-coding","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Using the Validate App for manual coding","title":"Using the Validate App","text":"Validate App launched, can start uploading dataset. app supports .csv .rds file formats. uploading data, can select column containing content (e.g., texts, images, etc.) want manually assess. using app, can manually assign score comments text item based coding scheme. can also save example sentences text item help remember coding decisions later illustrative examples research.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"reviewing-llm-generated-annotations","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Reviewing LLM-generated annotations","title":"Using the Validate App","text":"previously used quallmer package generate annotations using large language models (LLMs), can upload annotations Validate App review. app allows check LLM-generated codes alongside justifications provided model. can decide whether accept annotations valid invalid, modify based assessment adding comments example sentences.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"saving-your-coding-decisions","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Saving your coding decisions","title":"Using the Validate App","text":"app provides intuitive interface navigating data making coding decisions. coding decisions saved automatically, find newly created folder named “agreement” working directory.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"calculating-validation-scores","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Calculating validation scores","title":"Using the Validate App","text":"completing manual coding reviewing LLM-generated annotations, Validate App provides functionality calculate inter-rater reliability scores compare LLM annotations gold standard. can choose various metrics, Krippendorff’s alpha, Cohen’s Fleiss’ kappa, assess agreement different coders manual codes LLM annotations , shown , multiple LLM runs. app also provides interpretation guidelines help understand results. gold standard available, app calculate accuracy metrics precision, recall, F1-score.","code":""},{"path":[]},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"calculating-validation-scores-without-the-app","dir":"Articles > Pkgdown > Tutorials","previous_headings":"","what":"Calculating validation scores without the App","title":"Using the Validate App","text":"addition using Validate App, can also calculate agreement validation scores programmatically using functions quallmer package.","code":""},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"comparing-multiple-coders-inter-coder-reliability","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Calculating validation scores without the App","what":"Comparing multiple coders (inter-coder reliability)","title":"Using the Validate App","text":"gold standard available want assess inter-coder reliability multiple qlm_coded objects (different coders, models, coding runs), use qlm_compare(): compute agreement metrics including Krippendorff’s alpha, Cohen’s kappa, Fleiss’ kappa.","code":"# Compare two or more qlm_coded objects comparison <- qlm_compare(coded_run1, coded_run2, coded_run3) comparison"},{"path":"https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.html","id":"validating-against-a-gold-standard","dir":"Articles > Pkgdown > Tutorials","previous_headings":"Calculating validation scores without the App","what":"Validating against a gold standard","title":"Using the Validate App","text":"gold standard available want assess accuracy LLM-generated annotations gold standard, use qlm_validate(): compute classification metrics including accuracy, precision, recall, F1-score, Cohen’s kappa.","code":"# Validate LLM coding against gold standard validation <- qlm_validate(   coded_object = llm_coded_result,   gold_standard = gold_standard_data,   gold_column = \"manual_code\" ) validation"},{"path":"https://seraphinem.github.io/quallmer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Seraphine F. Maerz. Author, maintainer. Kenneth Benoit. Author.","code":""},{"path":"https://seraphinem.github.io/quallmer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Maerz S, Benoit K (2026). quallmer: Qualitative Analysis Large Language Models. R package version 0.2.0, https://seraphinem.github.io/quallmer/.","code":"@Manual{,   title = {quallmer: Qualitative Analysis with Large Language Models},   author = {Seraphine F. Maerz and Kenneth Benoit},   year = {2026},   note = {R package version 0.2.0},   url = {https://seraphinem.github.io/quallmer/}, }"},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"quallmer-","dir":"","previous_headings":"","what":"Qualitative Analysis with Large Language Models","title":"Qualitative Analysis with Large Language Models","text":"quallmer package easy--use toolbox quickly apply AI-assisted qualitative coding large amounts texts, images, pdfs, tabular data structured data. Using qlm_code(), users can apply codebook-based qualitative coding powered large language models (LLMs) generate structured, interpretable outputs. package includes built-codebooks common applications allows researchers create custom codebooks tailored specific research questions using qlm_codebook(). ensure quality reliability AI-generated coding, quallmer provides qlm_compare() evaluating inter-rater reliability qlm_validate() assessing accuracy gold standards. qlm_replicate(), researchers can systematically compare results across different models settings assess sensitivity reproducibility. quallmer trail system automatically captures provenance metadata full workflow traceability using qlm_trail() related functions. quallmer package makes AI-assisted qualitative coding accessible without requiring deep expertise R, programming machine learning.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_codebook","dir":"","previous_headings":"Coding and validation workflow","what":"qlm_codebook()","title":"Qualitative Analysis with Large Language Models","text":"Creates custom codebooks tailored specific research questions data types. Uses instructions type specifications ellmer define coding instructions output structure. Example codebook objects (e.g., data_codebook_sentiment, data_codebook_stance, data_codebook_ideology) demonstrate complete workflows common qualitative coding tasks. Extensible framework allows researchers define domain-specific coding schemes.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_code","dir":"","previous_headings":"Coding and validation workflow","what":"qlm_code()","title":"Qualitative Analysis with Large Language Models","text":"Applies LLM-based coding qualitative data using qlm_codebook. Works LLM supported ellmer. Returns qlm_coded object containing coded results metadata reproducibility.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_compare","dir":"","previous_headings":"Coding and validation workflow","what":"qlm_compare()","title":"Qualitative Analysis with Large Language Models","text":"Compares multiple qlm_coded objects assess inter-rater reliability. Computes agreement metrics including Krippendorff’s alpha, Cohen’s kappa, Fleiss’ kappa. Useful evaluating consistency across different coders, models, coding runs.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_validate","dir":"","previous_headings":"Coding and validation workflow","what":"qlm_validate()","title":"Qualitative Analysis with Large Language Models","text":"Validates LLM-coded output gold standard human coding. Computes classification metrics: accuracy, precision, recall, F1-score, Cohen’s kappa. Supports multiple averaging methods (macro, micro, weighted) per-class breakdowns.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_replicate","dir":"","previous_headings":"Replication","what":"qlm_replicate()","title":"Qualitative Analysis with Large Language Models","text":"Re-executes coding optional overrides (different models, codebooks, parameters). Tracks provenance chain comparing results across different configurations. Enables systematic assessment coding reliability sensitivity model choices.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"the-quallmer-trail","dir":"","previous_headings":"","what":"The quallmer trail","title":"Qualitative Analysis with Large Language Models","text":"qlm_coded, qlm_comparison, qlm_validation objects automatically capture provenance metadata including model parameters, timestamps, parent-child relationships. enables full workflow traceability. also allows users assess impact different models settings coding results well downstream analyses.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_trail","dir":"","previous_headings":"The quallmer trail","what":"qlm_trail()","title":"Qualitative Analysis with Large Language Models","text":"Extracts displays complete provenance chain coded objects. Shows history coding runs including model parameters, timestamps, parent relationships. Reconstructs full lineage following parent-child references across multiple objects. Automatically captures branching workflows multiple coded objects compared validated.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"qlm_trail_save-qlm_trail_export-qlm_trail_report","dir":"","previous_headings":"The quallmer trail","what":"qlm_trail_save(), qlm_trail_export(), qlm_trail_report()","title":"Qualitative Analysis with Large Language Models","text":"Save: Archive provenance trails RDS format long-term storage. Export: Convert trails JSON format portability integration tools. Report: Generate human-readable Quarto/RMarkdown documents summarizing complete workflow history, including assessment impact different models settings coding results downstream analyses.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"interactive-validation","dir":"","previous_headings":"","what":"Interactive validation","title":"Qualitative Analysis with Large Language Models","text":"interactive Shiny application perform manual coding, review AI-generated annotations, compute agreement metrics, see companion package quallmer.app.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"supported-llms","dir":"","previous_headings":"","what":"Supported LLMs","title":"Qualitative Analysis with Large Language Models","text":"package supports LLMs currently available ellmer package. authentication usage LLMs, please refer respective ellmer documentation see tutorial setting OpenAI API key getting started open-source Ollama model.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Qualitative Analysis with Large Language Models","text":"can install development version quallmer https://github.com/SeraphineM/quallmer :","code":"# install.packages(\"pak\") pak::pak(\"SeraphineM/quallmer\")"},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"example-use-and-tutorials","dir":"","previous_headings":"","what":"Example use and tutorials","title":"Qualitative Analysis with Large Language Models","text":"learn use package, please refer step--step tutorials example codebook illustrating complete workflow.","code":""},{"path":"https://seraphinem.github.io/quallmer/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Qualitative Analysis with Large Language Models","text":"Development package assisted Claude Code, AI coding assistant Anthropic, code refactoring, documentation updates, package restructuring.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply an annotation task to input data (deprecated) — annotate","text":"","code":"annotate(.data, task, model_name, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply an annotation task to input data (deprecated) — annotate","text":"task task object created task() qlm_codebook(). ... Additional arguments passed ellmer::chat(), ellmer::parallel_chat_structured(), ellmer::batch_chat_structured(), based argument name. Arguments recognized ellmer::parallel_chat_structured() take priority overlaps. Batch-specific arguments (path, wait, ignore_hash) used batch = TRUE. Arguments recognized function generate warning.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply an annotation task to input data (deprecated) — annotate","text":"data frame one row per input element, containing: id Identifier input (names sequential integers). ... Additional columns defined task's schema.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply an annotation task to input data (deprecated) — annotate","text":"annotate() deprecated favor qlm_code(). new function returns richer object includes metadata settings reproducibility.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/annotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply an annotation task to input data (deprecated) — annotate","text":"","code":"if (FALSE) { # \\dontrun{ # Deprecated usage texts <- c(\"I love this product!\", \"This is terrible.\") annotate(texts, task_sentiment(), model_name = \"openai\")  # New recommended usage coded <- qlm_code(texts, task_sentiment(), model = \"openai\") coded  # Print as tibble } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/as_qlm_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert objects to qlm_codebook — as_qlm_codebook","title":"Convert objects to qlm_codebook — as_qlm_codebook","text":"Generic function convert objects qlm_codebook class.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/as_qlm_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert objects to qlm_codebook — as_qlm_codebook","text":"","code":"as_qlm_codebook(x, ...)  # S3 method for class 'task' as_qlm_codebook(x, ...)  # S3 method for class 'qlm_codebook' as_qlm_codebook(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/as_qlm_codebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert objects to qlm_codebook — as_qlm_codebook","text":"x object convert qlm_codebook. ... Additional arguments passed methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/as_qlm_codebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert objects to qlm_codebook — as_qlm_codebook","text":"qlm_codebook object.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_fact.html","id":null,"dir":"Reference","previous_headings":"","what":"Fact-checking codebook — data_codebook_fact","title":"Fact-checking codebook — data_codebook_fact","text":"qlm_codebook object defining instructions assessing truthfulness accuracy texts.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_fact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fact-checking codebook — data_codebook_fact","text":"","code":"data_codebook_fact"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_fact.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fact-checking codebook — data_codebook_fact","text":"qlm_codebook object containing: name Task name: \"Fact-checking\" instructions Coding instructions truthfulness assessment schema Response schema three fields: role Expert fact-checker persona input_type \"text\"","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_fact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fact-checking codebook — data_codebook_fact","text":"","code":"if (FALSE) { # \\dontrun{ # View the codebook data_codebook_fact  # Use with claims or articles # NEEDS ACTUAL DATA coded <- qlm_code(claims,                   data_codebook_fact,                   model = \"openai/gpt-4o-mini\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_ideology.html","id":null,"dir":"Reference","previous_headings":"","what":"Ideological scaling codebook for left-right dimension — data_codebook_ideology","title":"Ideological scaling codebook for left-right dimension — data_codebook_ideology","text":"qlm_codebook object defining instructions scaling texts left-right ideological dimension.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_ideology.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ideological scaling codebook for left-right dimension — data_codebook_ideology","text":"","code":"data_codebook_ideology"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_ideology.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ideological scaling codebook for left-right dimension — data_codebook_ideology","text":"qlm_codebook object containing: name Task name: \"Ideological scaling\" instructions Coding instructions ideological scaling schema Response schema two fields: role Expert political scientist persona input_type \"text\"","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_ideology.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ideological scaling codebook for left-right dimension — data_codebook_ideology","text":"","code":"if (FALSE) { # \\dontrun{ # View the codebook data_codebook_ideology  # Use with political texts coded <- qlm_code(tail(quanteda::data_corpus_inaugural),                   data_codebook_ideology,                   model = \"openai/gpt-4o-mini\") coded } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_salience.html","id":null,"dir":"Reference","previous_headings":"","what":"Topic salience codebook — data_codebook_salience","title":"Topic salience codebook — data_codebook_salience","text":"qlm_codebook object defining instructions extracting ranking topics discussed texts salience.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_salience.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Topic salience codebook — data_codebook_salience","text":"","code":"data_codebook_salience"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_salience.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Topic salience codebook — data_codebook_salience","text":"qlm_codebook object containing: name Task name: \"Salience (ranked topics)\" instructions Coding instructions topic salience ranking schema Response schema two fields: role Expert content analyst persona input_type \"text\"","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_salience.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Topic salience codebook — data_codebook_salience","text":"","code":"if (FALSE) { # \\dontrun{ # View the codebook data_codebook_salience  # Use with documents coded <- qlm_code(tail(quanteda::data_corpus_inaugural),                   data_codebook_salience,                   model = \"openai/gpt-4o-mini\") coded } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Sentiment analysis codebook for movie reviews — data_codebook_sentiment","title":"Sentiment analysis codebook for movie reviews — data_codebook_sentiment","text":"qlm_codebook object defining instructions sentiment analysis movie reviews. Designed work data_corpus_LMRDsample expanded polarity scale includes \"mixed\" category.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sentiment analysis codebook for movie reviews — data_codebook_sentiment","text":"","code":"data_codebook_sentiment"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_sentiment.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sentiment analysis codebook for movie reviews — data_codebook_sentiment","text":"qlm_codebook object containing: name Task name: \"Movie Review Sentiment\" instructions Coding instructions analyzing movie review sentiment schema Response schema two fields: role Expert film critic persona input_type \"text\"","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sentiment analysis codebook for movie reviews — data_codebook_sentiment","text":"","code":"if (FALSE) { # \\dontrun{ # View the codebook data_codebook_sentiment  # Use with movie review corpus coded <- qlm_code(data_corpus_LMRDsample[1:10],                   data_codebook_sentiment,                   model = \"openai\")  # Create multiple coded versions for comparison coded1 <- qlm_code(data_corpus_LMRDsample[1:20],                    data_codebook_sentiment,                    model = \"openai/gpt-4o-mini\") coded2 <- qlm_code(data_corpus_LMRDsample[1:20],                    data_codebook_sentiment,                    model = \"openai/gpt-4o\")  # Compare inter-rater reliability comparison <- qlm_compare(coded1, coded2, by = \"rating\", level = \"interval\") print(comparison) } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_stance.html","id":null,"dir":"Reference","previous_headings":"","what":"Stance detection codebook for climate change — data_codebook_stance","title":"Stance detection codebook for climate change — data_codebook_stance","text":"qlm_codebook object defining instructions detecting stance towards climate change texts.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_stance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stance detection codebook for climate change — data_codebook_stance","text":"","code":"data_codebook_stance"},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_stance.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Stance detection codebook for climate change — data_codebook_stance","text":"qlm_codebook object containing: name Task name: \"Stance detection\" instructions Coding instructions classifying stance schema Response schema two fields: role Expert annotator persona input_type \"text\"","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/data_codebook_stance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stance detection codebook for climate change — data_codebook_stance","text":"","code":"if (FALSE) { # \\dontrun{ # View the codebook data_codebook_stance  # Use with text data coded <- qlm_code(tail(quanteda::data_corpus_inaugural),                   data_codebook_stance,                   model = \"openai/gpt-4o-mini\")  coded } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"sample 100 positive 100 negative reviews Maas et al. (2011) dataset sentiment classification.  original dataset contains 50,000 highly polar movie reviews.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"","code":"data_corpus_LMRDsample"},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"corpus docvars consist : docnumber serial (within set polarity) document number rating user-assigned movie rating 1-10 point integer scale polarity either neg pos indicate whether movie review negative positive.  See Maas et al (2011) cut-values governed assignment.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"http://ai.stanford.edu/~amaas/data/sentiment/","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, Christopher Potts. (2011). \"Learning Word Vectors Sentiment Analysis\". 49th Annual Meeting Association Computational Linguistics (ACL 2011).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from Large Movie Review Dataset (Maas et al. 2011) — data_corpus_LMRDsample","text":"","code":"if (FALSE) { # \\dontrun{ library(quanteda)  # define a sentiment codebook codebook_posneg <- qlm_codebook(   name = \"Sentiment analysis of movie reviews\",   instructions = \"You will rate the sentiment from movie reviews.\",   schema = type_object(     polarity = type_enum(c(\"pos\", \"neg\"),     description = \"Sentiment label (pos = positive, neg = negative\")   ) )  set.seed(10001) test_corpus <- data_corpus_LMRDsample %>%   corpus_sample(size = 10, by = polarity)  result <- qlm_code(test_corpus, codebook_posneg, model = \"openai/gpt-4o-mini\")  # Create gold standard from corpus metadata gold <- data.frame(.id = result$.id, polarity = test_corpus$polarity)  # Validate against human annotations qlm_validate(result, gold, by = \"polarity\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_manifsentsUK2010sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample of UK manifesto sentences 2010 crowd-annotated for immigration — data_corpus_manifsentsUK2010sample","title":"Sample of UK manifesto sentences 2010 crowd-annotated for immigration — data_corpus_manifsentsUK2010sample","text":"corpus sentences sampled publicly available party manifestos United Kingdom 2010 election.  sentence rated terms classification pertaining immigration scale favorability toward open immigration policy (mean score crowd coders scale -1 (favours open immigration policy), 0 (neutral), 1 (anti-immigration). sentences sampled corpus used Benoit et al. (2016), contains information crowd-sourced annotation  approach.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_manifsentsUK2010sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample of UK manifesto sentences 2010 crowd-annotated for immigration — data_corpus_manifsentsUK2010sample","text":"","code":"data_corpus_manifsentsUK2010sample"},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_manifsentsUK2010sample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample of UK manifesto sentences 2010 crowd-annotated for immigration — data_corpus_manifsentsUK2010sample","text":"corpus object. corpus consists 155 sentences randomly sampled party manifestos, attempt balance sentencs according categorisation pertaining immigration , well party. corpus contains following document-level variables: party factor; abbreviation party wrote manifesto. partyname factor; party wrote manifesto. year integer; 4-digit year election. crowd_immigration_label Factor indicating whether majority crowd workers labelled sentence referring immigration . variable missing values (NA) non-annotated manifestos. crowd_immigration_mean numeric; direction statements coded \"Immigration\" based aggregated crowd codings. variable mean scores assigned workers coded sentence allocated sentence \"Immigration\" category. variable ranges -1 (Favorable open immigration policy) +1 (\"Negative closed immigration policy\"). crowd_immigration_n integer; number coders contributed mean score crowd_immigration_mean.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/data_corpus_manifsentsUK2010sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample of UK manifesto sentences 2010 crowd-annotated for immigration — data_corpus_manifsentsUK2010sample","text":"Benoit, K., Conway, D., Lauderdale, B.E., Laver, M., & Mikhaylov, S. (2016). Crowd-sourced Text Analysis: Reproducible Agile Production Political Data. American Political Science Review, 100,(2), 278–295.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/print.corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for corpus objects — print.corpus","title":"Print method for corpus objects — print.corpus","text":"Provides simple print method corpus objects quanteda loaded. displays basic information corpus structure without requiring quanteda dependency.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for corpus objects — print.corpus","text":"","code":"# S3 method for class 'corpus' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for corpus objects — print.corpus","text":"x corpus object ... additional arguments (used)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a qlm_codebook object — print.qlm_codebook","title":"Print a qlm_codebook object — print.qlm_codebook","text":"Print qlm_codebook object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a qlm_codebook object — print.qlm_codebook","text":"","code":"# S3 method for class 'qlm_codebook' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_codebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a qlm_codebook object — print.qlm_codebook","text":"x qlm_codebook object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_codebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a qlm_codebook object — print.qlm_codebook","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_coded.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a qlm_coded object — print.qlm_coded","title":"Print a qlm_coded object — print.qlm_coded","text":"Print qlm_coded object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_coded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a qlm_coded object — print.qlm_coded","text":"","code":"# S3 method for class 'qlm_coded' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_coded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a qlm_coded object — print.qlm_coded","text":"x qlm_coded object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_coded.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a qlm_coded object — print.qlm_coded","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a qlm_comparison object — print.qlm_comparison","title":"Print a qlm_comparison object — print.qlm_comparison","text":"Print qlm_comparison object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a qlm_comparison object — print.qlm_comparison","text":"","code":"# S3 method for class 'qlm_comparison' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a qlm_comparison object — print.qlm_comparison","text":"x qlm_comparison object ... Additional arguments (currently unused)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_comparison.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a qlm_comparison object — print.qlm_comparison","text":"Invisibly returns input object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_robustness.html","id":null,"dir":"Reference","previous_headings":"","what":"Print robustness results — print.qlm_robustness","title":"Print robustness results — print.qlm_robustness","text":"Print robustness results","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_robustness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print robustness results — print.qlm_robustness","text":"","code":"# S3 method for class 'qlm_robustness' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_robustness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print robustness results — print.qlm_robustness","text":"x qlm_robustness object. ... Additional arguments (currently unused).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_robustness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print robustness results — print.qlm_robustness","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_trail.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a quallmer trail — print.qlm_trail","title":"Print a quallmer trail — print.qlm_trail","text":"Print quallmer trail","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_trail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a quallmer trail — print.qlm_trail","text":"","code":"# S3 method for class 'qlm_trail' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_trail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a quallmer trail — print.qlm_trail","text":"x qlm_trail object. ... Additional arguments (currently unused).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_trail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a quallmer trail — print.qlm_trail","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a qlm_validation object — print.qlm_validation","title":"Print a qlm_validation object — print.qlm_validation","text":"Print qlm_validation object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a qlm_validation object — print.qlm_validation","text":"","code":"# S3 method for class 'qlm_validation' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a qlm_validation object — print.qlm_validation","text":"x qlm_validation object. ... Additional arguments (currently unused).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.qlm_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a qlm_validation object — print.qlm_validation","text":"Invisibly returns input object.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.task.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a task object — print.task","title":"Print a task object — print.task","text":"Print task object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.task.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a task object — print.task","text":"","code":"# S3 method for class 'task' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.task.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a task object — print.task","text":"x task object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.task.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a task object — print.task","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a trail_compare object — print.trail_compare","title":"Print a trail_compare object — print.trail_compare","text":"Print trail_compare object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a trail_compare object — print.trail_compare","text":"","code":"# S3 method for class 'trail_compare' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a trail_compare object — print.trail_compare","text":"x trail_compare object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a trail_compare object — print.trail_compare","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_record.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a trail_record object — print.trail_record","title":"Print a trail_record object — print.trail_record","text":"Print trail_record object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_record.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a trail_record object — print.trail_record","text":"","code":"# S3 method for class 'trail_record' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_record.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a trail_record object — print.trail_record","text":"x trail_record object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_record.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a trail_record object — print.trail_record","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_setting.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a trail_setting object — print.trail_setting","title":"Print a trail_setting object — print.trail_setting","text":"Print trail_setting object","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_setting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a trail_setting object — print.trail_setting","text":"","code":"# S3 method for class 'trail_setting' print(x, ...)"},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_setting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a trail_setting object — print.trail_setting","text":"x trail_setting object. ... Additional arguments passed print methods.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/print.trail_setting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a trail_setting object — print.trail_setting","text":"Invisibly returns input object x. Called side effects (printing console).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Code qualitative data with an LLM — qlm_code","title":"Code qualitative data with an LLM — qlm_code","text":"Applies codebook input data using large language model, returning rich object includes codebook, execution settings, results, metadata reproducibility.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Code qualitative data with an LLM — qlm_code","text":"","code":"qlm_code(x, codebook, model, ..., batch = FALSE, name = \"original\")"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Code qualitative data with an LLM — qlm_code","text":"x Input data: character vector texts (text codebooks) file paths images (image codebooks). Named vectors use names identifiers output; unnamed vectors use sequential integers. codebook codebook object created qlm_codebook(). Also accepts deprecated task() objects backward compatibility. model Provider (optionally model) name form \"provider/model\" \"provider\" (use default model provider). Passed name argument ellmer::chat(). Examples: \"openai/gpt-4o-mini\", \"anthropic/claude-3-5-sonnet-20241022\", \"ollama/llama3.2\", \"openai\" (uses default OpenAI model). ... Additional arguments passed ellmer::chat(), ellmer::parallel_chat_structured(), ellmer::batch_chat_structured(), based argument name. Arguments recognized ellmer::parallel_chat_structured() take priority overlaps. Batch-specific arguments (path, wait, ignore_hash) used batch = TRUE. Arguments recognized function generate warning. batch Logical. TRUE, uses ellmer::batch_chat_structured() instead ellmer::parallel_chat_structured(). Batch processing cost-effective large jobs may longer turnaround times. Default FALSE. See ellmer::batch_chat_structured() details. name Character string identifying coding run. Default \"original\".","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Code qualitative data with an LLM — qlm_code","text":"qlm_coded object (tibble additional attributes): Data columns coded results .id column identifiers. Attributes data, input_type, run (list containing name, batch, call, codebook, chat_args, execution_args, metadata, parent). object prints tibble can used directly data manipulation workflows. batch flag run attribute indicates whether batch processing used. execution_args contains non-chat execution arguments (either parallel batch processing).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Code qualitative data with an LLM — qlm_code","text":"Arguments ... dynamically routed either ellmer::chat(), ellmer::parallel_chat_structured(), ellmer::batch_chat_structured() based names. Progress indicators error handling provided underlying ellmer::parallel_chat_structured() ellmer::batch_chat_structured() function. Set verbose = TRUE see progress messages coding. Retry logic API failures configured ellmer's options. batch = TRUE, function uses ellmer::batch_chat_structured() submits jobs provider's batch API. typically cost-effective longer turnaround times. path argument specifies batch results cached, wait controls whether wait completion, ignore_hash can force reprocessing cached results.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Code qualitative data with an LLM — qlm_code","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(24) texts <- data_corpus_LMRDsample[sample(length(data_corpus_LMRDsample), size = 20)]  # Basic sentiment analysis coded <- qlm_code(texts, data_codebook_sentiment, model = \"openai\") coded  # Print results as tibble  # With named inputs (names become IDs in output) texts <- c(doc1 = \"Great service!\", doc2 = \"Very disappointing.\") coded <- qlm_code(texts, data_codebook_sentiment, model = \"openai\")  # Specify provider and model coded <- qlm_code(texts, data_codebook_sentiment, model = \"openai/gpt-4o-mini\")  # With execution control coded <- qlm_code(texts, data_codebook_sentiment,                   model = \"openai/gpt-4o-mini\",                   params = params(temperature = 0))  # Include token usage and cost coded <- qlm_code(texts, data_codebook_sentiment,                   model = \"openai\",                   include_tokens = TRUE,                   include_cost = TRUE) coded  # Use batch processing for cost-effective large-scale coding coded_batch <- qlm_code(texts, data_codebook_sentiment,                         model = \"openai\",                         batch = TRUE,                         path = \"batch_results.json\",                         ignore_hash = TRUE,                         include_cost = TRUE) coded_batch } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a qualitative codebook — qlm_codebook","title":"Define a qualitative codebook — qlm_codebook","text":"Creates codebook definition use qlm_code(). codebook specifies information extract input data, including instructions guide LLM structured output schema.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a qualitative codebook — qlm_codebook","text":"","code":"qlm_codebook(   name,   instructions,   schema,   role = NULL,   input_type = c(\"text\", \"image\") )"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a qualitative codebook — qlm_codebook","text":"name Name codebook (character). instructions Instructions guide model performing coding task. schema Structured output definition, e.g., created ellmer::type_object(), ellmer::type_array(), ellmer::type_enum(). role Optional role description model (e.g., \"expert annotator\"). provided, prepended instructions creating system prompt. input_type Type input data: \"text\" (default) \"image\".","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a qualitative codebook — qlm_codebook","text":"codebook object (list class c(\"qlm_codebook\", \"task\")) containing codebook definition. Use qlm_code() apply codebook data.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a qualitative codebook — qlm_codebook","text":"function replaces task(), now deprecated. returned object dual class inheritance (c(\"qlm_codebook\", \"task\")) maintain backward compatibility existing code using annotate().","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_codebook.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a qualitative codebook — qlm_codebook","text":"","code":"if (FALSE) { # \\dontrun{ # Define a custom codebook my_codebook <- qlm_codebook(   name = \"Sentiment\",   instructions = \"Rate the sentiment from -1 (negative) to 1 (positive).\",   schema = type_object(     score = type_number(\"Sentiment score from -1 to 1\"),     explanation = type_string(\"Brief explanation\")   ) )  # With a role my_codebook <- qlm_codebook(   name = \"Sentiment\",   instructions = \"Rate the sentiment from -1 (negative) to 1 (positive).\",   schema = type_object(     score = type_number(\"Sentiment score from -1 to 1\"),     explanation = type_string(\"Brief explanation\")   ),   role = \"You are an expert sentiment analyst.\" )  # Use with qlm_code() texts <- c(\"I love this!\", \"This is terrible.\") coded <- qlm_code(texts, my_codebook, model = \"openai/gpt-4o-mini\") coded  # Print results as tibble } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare coded results for inter-rater reliability — qlm_compare","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"Compares two qlm_coded objects assess inter-rater reliability agreement. function extracts specified variable coded result computes reliability statistics using irr package.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"","code":"qlm_compare(   ...,   by,   level = c(\"nominal\", \"ordinal\", \"interval\", \"ratio\"),   tolerance = 0 )"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"... Two qlm_coded objects compare. represent different \"raters\" (e.g., different LLM runs, different models, human vs. LLM coding). Objects units (matching .id values). Name variable compare across raters (supports quoted unquoted). Must present qlm_coded objects. Can specified = sentiment = \"sentiment\". level Character scalar. Measurement level variable: \"nominal\", \"ordinal\", \"interval\", \"ratio\". Default \"nominal\". Different sets agreement statistics computed level. tolerance Numeric. Tolerance agreement numeric data. Default 0 (exact agreement required). Used percent agreement calculation.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"qlm_comparison object containing agreement statistics appropriate measurement level: Nominal level: alpha_nominal: Krippendorff's alpha kappa: Cohen's kappa (2 raters) Fleiss' kappa (3+ raters) kappa_type: Character indicating \"Cohen's\" \"Fleiss'\" percent_agreement: Simple percent agreement Ordinal level: alpha_ordinal: Krippendorff's alpha (ordinal) kappa_weighted: Weighted kappa (2 raters ) w: Kendall's W coefficient concordance rho: Spearman's rho percent_agreement: Simple percent agreement Interval level: alpha_interval: Krippendorff's alpha (interval) icc: Intraclass correlation coefficient r: Pearson's r percent_agreement: Simple percent agreement Ratio level: Measures interval level, Krippendorff's alpha computed using ratio-level formula. alpha_ratio: Krippendorff's alpha (ratio) icc: Intraclass correlation coefficient r: Pearson's r percent_agreement: Simple percent agreement subjects Number units compared raters Number raters level Measurement level call function call","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"function merges coded objects .id column includes units present objects. Missing values rater exclude unit analysis. Measurement levels statistics: Nominal: unordered categories. Computes Krippendorff's alpha, Cohen's/Fleiss' kappa, percent agreement. Ordinal: ordered categories. Computes Krippendorff's alpha (ordinal), weighted kappa (2 raters ), Kendall's W, Spearman's rho, percent agreement. Interval: continuous data meaningful intervals. Computes Krippendorff's alpha (interval), ICC, Pearson's r, percent agreement. Ratio: continuous data true zero point. Computes measures interval level, Krippendorff's alpha uses ratio-level formula accounts proportional differences. Kendall's W, ICC, percent agreement computed using raters simultaneously. 3 raters, Spearman's rho Pearson's r computed mean pairwise correlations raters.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare coded results for inter-rater reliability — qlm_compare","text":"","code":"if (FALSE) { # \\dontrun{ # Compare two LLM coding runs on movie reviews set.seed(42) reviews <- data_corpus_LMRDsample[sample(length(data_corpus_LMRDsample), size = 20)] coded1 <- qlm_code(reviews, data_codebook_sentiment, model = \"openai/gpt-4o-mini\") coded2 <- qlm_code(reviews, data_codebook_sentiment, model = \"openai/gpt-4o\")  # Compare nominal data (polarity: neg/pos) - supports unquoted variable names qlm_compare(coded1, coded2, by = sentiment, level = \"nominal\")  # Can also use quoted names qlm_compare(coded1, coded2, by = \"sentiment\", level = \"nominal\")  # Compare ordinal data (rating: 1-10) qlm_compare(coded1, coded2, by = rating, level = \"ordinal\")  # Compare three raters using Fleiss' kappa on polarity coded3 <- qlm_replicate(coded1, params = params(temperature = 0.5)) qlm_compare(coded1, coded2, coded3, by = sentiment, level = \"nominal\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_replicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Replicate a coding task — qlm_replicate","title":"Replicate a coding task — qlm_replicate","text":"Re-executes coding task qlm_coded object, optionally modified settings. overrides provided, uses identical settings original coding.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_replicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replicate a coding task — qlm_replicate","text":"","code":"qlm_replicate(x, ..., codebook = NULL, model = NULL, batch = NULL, name = NULL)"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_replicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replicate a coding task — qlm_replicate","text":"x qlm_coded object. ... Optional overrides passed qlm_code(), temperature max_tokens. codebook Optional replacement codebook. NULL (default), uses codebook x. model Optional replacement model (e.g., \"openai/gpt-4o\"). NULL (default), uses model x. batch Optional logical override batch processing setting. NULL (default), uses batch setting x. Set TRUE use batch processing FALSE use parallel processing, regardless original setting. name Optional name run. NULL, defaults model name (changed) \"replication_N\" N replication count.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_replicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replicate a coding task — qlm_replicate","text":"qlm_coded object run$parent set parent's run name.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_replicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replicate a coding task — qlm_replicate","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(24) reviews <- data_corpus_LMRDsample[sample(length(data_corpus_LMRDsample), size = 20)]  # Code movie reviews coded <- qlm_code(   reviews,   data_codebook_sentiment,   model = \"openai/gpt-4o\" )  # Replicate with different model coded2 <- qlm_replicate(coded, model = \"openai/gpt-4o-mini\")  # Replicate using batch processing for cost savings coded3 <- qlm_replicate(coded, batch = TRUE, path = \"batch_results.json\")  # Compare results qlm_compare(coded, coded2, coded3, by = \"sentiment\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract provenance trail from quallmer objects — qlm_trail","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"Extracts displays provenance chain one qlm_coded, qlm_comparison, qlm_validation objects. multiple objects provided, attempts reconstruct full lineage matching parent-child relationships.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"","code":"qlm_trail(...)"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"... One quallmer objects (qlm_coded, qlm_comparison, qlm_validation). multiple objects provided, used reconstruct complete provenance chain.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"qlm_trail object containing: runs List run information, ordered oldest newest complete Logical indicating whether parent references resolved","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"provenance trail shows history coding runs, including: Run name parent relationship Model parameters used Timestamp Call created run single object provided, immediate lineage (name, parent, timestamp) shown. see full chain, provide ancestor objects. branching workflows (e.g., multiple coded objects compared), trail captures input runs parents comparison.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract provenance trail from quallmer objects — qlm_trail","text":"","code":"if (FALSE) { # \\dontrun{ # Single run shows immediate info coded1 <- qlm_code(reviews, codebook, model = \"openai/gpt-4o\") qlm_trail(coded1)  # Create replication chain coded2 <- qlm_replicate(coded1, model = \"openai/gpt-4o-mini\") coded3 <- qlm_replicate(coded2, temperature = 0.7)  # Reconstruct full chain trail <- qlm_trail(coded3, coded2, coded1) print(trail)  # Save for archival qlm_trail_save(trail, \"analysis_trail.rds\")  # Export to JSON qlm_trail_export(trail, \"analysis_trail.json\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":null,"dir":"Reference","previous_headings":"","what":"Export trail to JSON — qlm_trail_export","title":"Export trail to JSON — qlm_trail_export","text":"Exports provenance trail JSON format portability archival.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export trail to JSON — qlm_trail_export","text":"","code":"qlm_trail_export(trail, file)"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export trail to JSON — qlm_trail_export","text":"trail qlm_trail object qlm_trail(). file Path save JSON file.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export trail to JSON — qlm_trail_export","text":"Invisibly returns file path.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export trail to JSON — qlm_trail_export","text":"JSON export includes: Run names parent relationships Timestamps Model names parameters Codebook names Call information (text) Large objects like full codebook schema data included keep file sizes manageable.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_export.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export trail to JSON — qlm_trail_export","text":"","code":"if (FALSE) { # \\dontrun{ trail <- qlm_trail(coded1, coded2, coded3) qlm_trail_export(trail, \"analysis_trail.json\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate trail report — qlm_trail_report","title":"Generate trail report — qlm_trail_report","text":"Generates human-readable Quarto/RMarkdown document summarizing provenance trail, optionally including assessment metrics across runs.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate trail report — qlm_trail_report","text":"","code":"qlm_trail_report(   trail,   file,   include_comparisons = FALSE,   include_validations = FALSE,   robustness = NULL )"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate trail report — qlm_trail_report","text":"trail qlm_trail object qlm_trail(). file Path save report file (.qmd .Rmd). include_comparisons Logical. TRUE, include comparison metrics report (comparisons trail). Default FALSE. include_validations Logical. TRUE, include validation metrics report (validations trail). Default FALSE. robustness Optional. qlm_robustness object qlm_trail_robustness() containing downstream analysis robustness metrics include report.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate trail report — qlm_trail_report","text":"Invisibly returns file path.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate trail report — qlm_trail_report","text":"Creates formatted document showing: Trail summary completeness Timeline runs Model parameters settings run Parent-child relationships Assessment metrics (requested): Inter-rater reliability comparisons Validation results gold standards Downstream analysis robustness generated file can rendered HTML, PDF, formats using Quarto RMarkdown.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate trail report — qlm_trail_report","text":"","code":"if (FALSE) { # \\dontrun{ # Basic trail report trail <- qlm_trail(coded1, coded2, coded3) qlm_trail_report(trail, \"analysis_trail.qmd\")  # Include comparison and validation metrics trail <- qlm_trail(coded1, coded2, comparison, validation) qlm_trail_report(trail, \"full_report.qmd\",                  include_comparisons = TRUE,                  include_validations = TRUE)  # Include robustness assessment robustness <- qlm_trail_robustness(coded1, coded2, coded3,                                    reference = \"run1\",                                    analysis_fn = my_analysis) qlm_trail_report(trail, \"full_report.qmd\", robustness = robustness)  # Render to HTML quarto::quarto_render(\"full_report.qmd\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"Assesses much downstream analysis results vary across different coding runs. helps determine whether substantive conclusions robust different models, parameters, codebook variations.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"","code":"qlm_trail_robustness(..., reference, analysis_fn)"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"... One qlm_coded objects. objects actual coded results (just trail). Must include reference run. reference Character string naming reference run compare . match name attribute one provided objects. analysis_fn function takes qlm_coded object returns named list data frame analysis results. function applied coded object compute downstream statistics.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"data frame robustness metrics: run Name run statistic Name analysis statistic value Value run reference_value Value reference run abs_diff Absolute difference reference pct_diff Percent difference reference (NULL reference 0)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"Robustness assessed : Applying analysis function coded object Comparing resulting statistics reference run Computing absolute percentage differences Smaller differences indicate robust findings depend heavily model choice. Large differences suggest conclusions may sensitive model settings use. analysis_fn return named list data frame element single numeric value representing statistic interest (e.g., mean, proportion, correlation coefficient, regression coefficient).","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_robustness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute robustness scale showing downstream analysis changes — qlm_trail_robustness","text":"","code":"if (FALSE) { # \\dontrun{ # Create multiple coded versions coded1 <- qlm_code(texts, codebook, model = \"openai/gpt-4o\",                    name = \"gpt4o_run\") coded2 <- qlm_replicate(coded1, model = \"openai/gpt-4o-mini\",                         name = \"mini_run\") coded3 <- qlm_replicate(coded1, temperature = 0.7,                         name = \"temp07_run\")  # Define downstream analysis function my_analysis <- function(coded) {   list(     mean_score = mean(coded$score, na.rm = TRUE),     prop_positive = mean(coded$sentiment == \"positive\", na.rm = TRUE),     sd_score = sd(coded$score, na.rm = TRUE)   ) }  # Compute robustness robustness <- qlm_trail_robustness(coded1, coded2, coded3,                                    reference = \"gpt4o_run\",                                    analysis_fn = my_analysis) print(robustness) } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Save trail to RDS file — qlm_trail_save","title":"Save trail to RDS file — qlm_trail_save","text":"Saves provenance trail RDS file archival purposes.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save trail to RDS file — qlm_trail_save","text":"","code":"qlm_trail_save(trail, file)"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save trail to RDS file — qlm_trail_save","text":"trail qlm_trail object qlm_trail(). file Path save RDS file.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_save.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save trail to RDS file — qlm_trail_save","text":"Invisibly returns file path.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_trail_save.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save trail to RDS file — qlm_trail_save","text":"","code":"if (FALSE) { # \\dontrun{ trail <- qlm_trail(coded1, coded2, coded3) qlm_trail_save(trail, \"analysis_trail.rds\") } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate coded results against a gold standard — qlm_validate","title":"Validate coded results against a gold standard — qlm_validate","text":"Validates LLM-coded results qlm_coded object gold standard (typically human annotations) using appropriate metrics based measurement level. nominal data, computes accuracy, precision, recall, F1-score, Cohen's kappa. ordinal data, computes accuracy weighted kappa (linear weighting), accounts ordering distance categories.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate coded results against a gold standard — qlm_validate","text":"","code":"qlm_validate(   x,   gold,   by,   level = c(\"nominal\", \"ordinal\", \"interval\"),   average = c(\"macro\", \"micro\", \"weighted\", \"none\") )"},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate coded results against a gold standard — qlm_validate","text":"x qlm_coded object containing LLM predictions validate. gold data frame containing gold standard annotations. Must include .id column joining x variable specified . (Can also qlm_coded object.) Name variable validate (supports quoted unquoted). Must present x gold. Can specified = sentiment = \"sentiment\". level Character scalar. Measurement level variable: \"nominal\", \"ordinal\", \"interval\". Default \"nominal\". Determines validation metrics computed. average Character scalar. Averaging method multiclass metrics (nominal level ): \"macro\" Unweighted mean across classes (default) \"micro\" Aggregate contributions globally (sum TP, FP, FN) \"weighted\" Weighted mean class prevalence \"none\" Return per-class metrics addition global metrics","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate coded results against a gold standard — qlm_validate","text":"qlm_validation object containing: accuracy Overall accuracy (nominal ) precision Precision (nominal ) recall Recall (nominal ) f1 F1-score (nominal ) kappa Cohen's kappa (nominal ) rho Spearman's rho rank correlation (ordinal ) tau Kendall's tau rank correlation (ordinal ) r Pearson's r correlation (interval ) icc Intraclass correlation coefficient (interval ) mae Mean absolute error (ordinal/interval) rmse Root mean squared error (interval ) by_class Per-class metrics (nominal average = \"none\" ) confusion Confusion matrix (nominal ) n Number units compared classes Class/level labels average Averaging method used level Measurement level variable Variable name validated call Function call","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate coded results against a gold standard — qlm_validate","text":"function performs inner join x gold using .id column, units present datasets included validation. Missing values (NA) either predictions gold standard excluded warning. Measurement levels: Nominal: Categories inherent ordering (e.g., topics, sentiment polarity). Metrics: accuracy, precision, recall, F1-score, Cohen's kappa (unweighted). Ordinal: Categories meaningful ordering unequal intervals (e.g., ratings 1-5, Likert scales). Metrics: Spearman's rho (rho, rank correlation), Kendall's tau (tau, rank correlation), MAE (mae, mean absolute error). measures account ordering categories without assuming equal intervals. Interval/Ratio: Numeric data equal intervals (e.g., counts, continuous measurements). Metrics: ICC (intraclass correlation), Pearson's r (linear correlation), MAE (mean absolute error), RMSE (root mean squared error). multiclass problems nominal data, average parameter controls per-class metrics aggregated: Macro averaging computes metrics class independently takes unweighted mean. treats classes equally regardless size. Micro averaging aggregates true positives, false positives, false negatives globally computing metrics. weights classes prevalence. Weighted averaging computes metrics class takes mean weighted class size. averaging (average = \"none\") returns global macro-averaged metrics plus per-class breakdown. Note: average parameter affects precision, recall, F1 nominal data. ordinal data, metrics computed.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/qlm_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate coded results against a gold standard — qlm_validate","text":"","code":"if (FALSE) { # \\dontrun{ # Basic validation against gold standard  set.seed(24) reviews <- data_corpus_LMRDsample[sample(length(data_corpus_LMRDsample), size = 20)]  # Code movie reviews coded <- qlm_code(   reviews,   data_codebook_sentiment,   model = \"openai/gpt-4o\" )  # Create gold standard from corpus metadata gold <- data.frame(   .id = coded$.id,   sentiment = quanteda::docvars(reviews, \"polarity\"),   rating = quanteda::docvars(reviews, \"rating\") )  # Validate polarity (nominal data) - supports unquoted variable names validation <- qlm_validate(coded, gold, by = sentiment, level = \"nominal\") print(validation)  # Can also use quoted names validation <- qlm_validate(coded, gold, by = \"sentiment\", level = \"nominal\")  # Validate ratings (ordinal data) validation_ordinal <- qlm_validate(coded, gold_ratings, by = rating, level = \"ordinal\") print(validation_ordinal)  # Use micro-averaging (nominal level only) qlm_validate(coded, gold, by = sentiment, level = \"nominal\", average = \"micro\")  # Get per-class breakdown (for nominal data only) validation_detailed <- qlm_validate(coded, gold, by = sentiment,                                     level = \"nominal\", average = \"none\") print(validation_detailed) validation_detailed$by_class validation_detailed$confusion } # }"},{"path":"https://seraphinem.github.io/quallmer/reference/quallmer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"quallmer: Qualitative Analysis with Large Language Models — quallmer-package","title":"quallmer: Qualitative Analysis with Large Language Models — quallmer-package","text":"Tools AI-assisted qualitative data coding using large language models (LLMs). Provides codebook-based workflow defining coding instructions applying texts, images, data. Includes built-codebooks common applications functions creating custom codebooks tailored specific research questions. Supports replication across models settings, computing inter-coder reliability gold-standard validation metrics.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/quallmer-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"quallmer: Qualitative Analysis with Large Language Models — quallmer-package","text":"Krippendorff, K. (2019). Content Analysis: Introduction Methodology. 4th ed. Thousand Oaks, CA: SAGE. doi:10.4135/9781071878781 Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5), 378–382. doi:10.1037/h0031619 Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20(1), 37–46. doi:10.1177/001316446002000104 Sokolova, M., & Lapalme, G. (2009). systematic analysis performance measures classification tasks. Information Processing & Management, 45(4), 427–437. doi:10.1016/j.ipm.2009.03.002 Wickham H, Cheng J, Jacobs , Aden-Buie G, Schloerke B (2025). ellmer: Chat Large Language Models. R package. https://github.com/tidyverse/ellmer","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/quallmer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"quallmer: Qualitative Analysis with Large Language Models — quallmer-package","text":"Maintainer: Seraphine F. Maerz seraphine.maerz@unimelb.edu.au (ORCID) Authors: Kenneth Benoit kbenoit@smu.edu.sg (ORCID)","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/sub-.corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset method for corpus objects — [.corpus","title":"Subset method for corpus objects — [.corpus","text":"Subset method corpus objects","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/sub-.corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset method for corpus objects — [.corpus","text":"","code":"# S3 method for class 'corpus' x[i, ...]"},{"path":"https://seraphinem.github.io/quallmer/reference/sub-.corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset method for corpus objects — [.corpus","text":"x corpus object index subsetting ... additional arguments","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define an annotation task (deprecated) — task","text":"","code":"task(name, system_prompt, type_def, input_type = c(\"text\", \"image\"))"},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define an annotation task (deprecated) — task","text":"name Name codebook (character). input_type Type input data: \"text\" (default) \"image\".","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define an annotation task (deprecated) — task","text":"task object (list class \"task\") containing task definition.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define an annotation task (deprecated) — task","text":"task() deprecated favor qlm_codebook(). new function returns object dual class inheritance works old new APIs.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/task.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define an annotation task (deprecated) — task","text":"","code":"if (FALSE) { # \\dontrun{ # Deprecated usage my_task <- task(   name = \"Sentiment\",   system_prompt = \"Rate the sentiment from -1 (negative) to 1 (positive).\",   type_def = type_object(     score = type_number(\"Sentiment score from -1 to 1\"),     explanation = type_string(\"Brief explanation\")   ) )  # New recommended usage my_codebook <- qlm_codebook(   name = \"Sentiment\",   instructions = \"Rate the sentiment from -1 (negative) to 1 (positive).\",   schema = type_object(     score = type_number(\"Sentiment score from -1 to 1\"),     explanation = type_string(\"Brief explanation\")   ) ) } # }"},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/trail_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"trail_compare: run a task across multiple settings and compute reliability (deprecated) — trail_compare","text":"","code":"trail_compare(   data,   text_col,   task,   settings,   id_col = NULL,   label_col = \"label\",   cache_dir = NULL,   overwrite = FALSE,   annotate_fun = annotate,   min_coders = 2L )"},{"path":"https://seraphinem.github.io/quallmer/reference/trail_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"trail_compare: run a task across multiple settings and compute reliability (deprecated) — trail_compare","text":"data data frame containing text annotated. text_col Character scalar. Name text column containing text units annotate. task quallmer task object describing extract label. settings named list trail_setting objects. list names serve identifiers setting (similar coder IDs). id_col Optional character scalar identifying unit column. NULL, consistent temporary ID (\".trail_unit_id\") created added input data annotations settings can aligned. label_col Character scalar. Name label column record's annotations data used code comparison (e.g. \"label\", \"score\", \"category\"). cache_dir Optional character scalar specifying directory cache LLM outputs. Passed trail_record(). NULL, caching disabled. examples tests, use tempdir() comply CRAN policies. overwrite Logical. TRUE, ignore cached results recompute annotations every setting. annotate_fun Annotation backend function used trail_record() (default = annotate()). min_coders Minimum number non-missing coders per unit required inclusion inter-rater reliability calculation.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"trail_compare: run a task across multiple settings and compute reliability (deprecated) — trail_compare","text":"trail_compare object components: records Named list trail_record objects (one per setting) matrix Wide coder-style annotation matrix (settings = columns) icr Named list inter-rater reliability statistics meta Metadata settings, identifiers, task, timestamp, etc.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"trail_compare: run a task across multiple settings and compute reliability (deprecated) — trail_compare","text":"trail_compare() deprecated. Use qlm_replicate() re-run coding different models settings, use qlm_compare() assess inter-rater reliability. settings applied text units. ID column shared across settings, annotation outputs can directly compared via matrix component, summarized using inter-rater reliability statistics icr.","code":""},{"path":[]},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/trail_icr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute inter-rater reliability across Trail settings (deprecated) — trail_icr","text":"","code":"trail_icr(   x,   id_col = \"id\",   label_col = \"label\",   min_coders = 2L,   icr_fun = validate,   ... )"},{"path":"https://seraphinem.github.io/quallmer/reference/trail_icr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute inter-rater reliability across Trail settings (deprecated) — trail_icr","text":"x trail_compare object list trail_record objects. id_col Character scalar. Name unit identifier column resulting wide data (defaults \"id\"). label_col Character scalar. Name label column record's annotations (defaults \"label\"). min_coders Integer. Minimum number non-missing coders per unit required inclusion. icr_fun Function used compute inter-rater reliability. Defaults validate(), expected accept data, id, coder_cols, min_coders, mode = \"icr\". also understand output = \"list\" return named list statistics. ... Additional arguments passed icr_fun.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_icr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute inter-rater reliability across Trail settings (deprecated) — trail_icr","text":"result calling icr_fun() wide data. default validate(), named list inter-rater reliability statistics.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_icr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute inter-rater reliability across Trail settings (deprecated) — trail_icr","text":"trail_icr() deprecated. Use qlm_compare() compute inter-rater reliability across multiple coded objects.","code":""},{"path":[]},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/trail_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Trail records to coder-style wide data (deprecated) — trail_matrix","text":"","code":"trail_matrix(x, id_col = \"id\", label_col = \"label\")"},{"path":"https://seraphinem.github.io/quallmer/reference/trail_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Trail records to coder-style wide data (deprecated) — trail_matrix","text":"x Either trail_compare object named list trail_record objects. id_col Character scalar. Name column identifies units (documents, paragraphs, etc.). Must present record's annotations data. label_col Character scalar. Name column record's annotations data containing code label interest.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Trail records to coder-style wide data (deprecated) — trail_matrix","text":"data frame one row per unit one column per setting/record. unit ID column retained name id_col.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Trail records to coder-style wide data (deprecated) — trail_matrix","text":"trail_matrix() deprecated. Use qlm_compare() compare multiple coded objects directly.","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/trail_record.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trail record: reproducible quallmer annotation (deprecated) — trail_record","text":"","code":"trail_record(   data,   text_col,   task,   setting,   id_col = NULL,   cache_dir = NULL,   overwrite = FALSE,   annotate_fun = annotate )"},{"path":"https://seraphinem.github.io/quallmer/reference/trail_record.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trail record: reproducible quallmer annotation (deprecated) — trail_record","text":"data data frame containing text annotated. text_col Character scalar. Name text column. task quallmer task object. setting trail_setting object describing LLM configuration. id_col Optional character scalar identifying units. cache_dir Optional directory cache Trails. NULL, caching disabled. examples tests, use tempdir() comply CRAN policies. overwrite Whether overwrite existing cache. annotate_fun Function used perform annotation (default annotate()).","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_record.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trail record: reproducible quallmer annotation (deprecated) — trail_record","text":"object class \"trail_record\".","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_record.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trail record: reproducible quallmer annotation (deprecated) — trail_record","text":"trail_record() deprecated. Use qlm_code() instead, automatically captures metadata reproducibility. systematic comparisons across different models settings, see qlm_replicate().","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/trail_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trail settings specification (deprecated) — trail_settings","text":"","code":"trail_settings(   provider = \"openai\",   model = \"gpt-4o-mini\",   temperature = 0,   extra = list() )"},{"path":"https://seraphinem.github.io/quallmer/reference/trail_settings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trail settings specification (deprecated) — trail_settings","text":"provider Character. Backend provider identifier supported ellmer, e.g. \"openai\", \"ollama\", \"anthropic\". See ellmer documentation supported providers. model Character. Model identifier, e.g. \"gpt-4o-mini\", \"llama3.2:1b\", \"claude-3-5-sonnet-20241022\". temperature Numeric scalar. Sampling temperature (default 0). Valid range depends provider: OpenAI (0-2), Anthropic (0-1), etc. extra Named list extra arguments merged api_args.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_settings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trail settings specification (deprecated) — trail_settings","text":"object class \"trail_setting\".","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/trail_settings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trail settings specification (deprecated) — trail_settings","text":"trail_settings() deprecated. Use qlm_code() model temperature parameters directly instead. systematic comparisons across different models settings, see qlm_replicate().","code":""},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"","code":"validate(   data,   id,   coder_cols,   min_coders = 2L,   mode = c(\"icr\", \"gold\"),   gold = NULL,   output = c(\"list\", \"data.frame\") )"},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"data data frame containing unit identifier coder columns. id Character scalar. Name column identifying units (e.g. document ID, paragraph ID). coder_cols Character vector. Names columns containing coders' codes (column = one coder). min_coders Integer: minimum number non-missing coders per unit unit included. Default 2. mode Character scalar: either \"icr\" inter-rater reliability statistics, \"gold\" compare coders gold-standard coder. gold Character scalar: name gold-standard coder column (must one coder_cols) mode = \"gold\". output Character scalar: either \"list\" (default) return named list metrics mode = \"icr\", \"data.frame\" return long data frame columns metric value. mode = \"gold\", result always data frame.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"mode = \"icr\": output = \"list\" (default): named list scalar metrics (e.g. res$fleiss_kappa). output = \"data.frame\": data frame columns metric value. mode = \"gold\": data frame one row per non-gold coder columns: coder_id Name coder column compared gold standard n Number units non-missing gold coder codes accuracy Overall accuracy precision_macro Macro-averaged precision across categories recall_macro Macro-averaged recall across categories f1_macro Macro-averaged F1 score across categories","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"function superseded qlm_compare() inter-rater reliability qlm_validate() gold-standard validation. function validates nominal coding data multiple coders two ways: Krippendorf's alpha (Krippendorf 2019) Fleiss's kappa (Fleiss 1971) inter-rater reliability statistics, gold-standard classification metrics following Sokolova Lapalme (2009). mode = \"icr\": compute inter-rater reliability statistics (Krippendorff's alpha (nominal), Fleiss' kappa, mean pairwise Cohen's kappa, mean pairwise percent agreement, share unanimous units, basic counts). mode = \"gold\": treat one coder column gold standard (typically human coder) , coder, compute accuracy, macro-averaged precision, recall, F1.","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"Krippendorff, K. (2019). Content Analysis: Introduction Methodology. 4th ed. Thousand Oaks, CA: SAGE. doi:10.4135/9781071878781 Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5), 378–382. doi:10.1037/h0031619 Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20(1), 37–46. doi:10.1177/001316446002000104 Sokolova, M., & Lapalme, G. (2009). systematic analysis performance measures classification tasks. Information Processing & Management, 45(4), 427–437. doi:10.1016/j.ipm.2009.03.002","code":""},{"path":"https://seraphinem.github.io/quallmer/reference/validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate coding: inter-rater reliability or gold-standard comparison — validate","text":"","code":"if (FALSE) { # \\dontrun{ # Inter-rater reliability (list output) res_icr <- validate(   data = my_df,   id   = \"doc_id\",   coder_cols  = c(\"coder1\", \"coder2\", \"coder3\"),   mode = \"icr\" ) res_icr$fleiss_kappa  # Inter-rater reliability (data.frame output) res_icr_df <- validate(   data = my_df,   id   = \"doc_id\",   coder_cols  = c(\"coder1\", \"coder2\", \"coder3\"),   mode   = \"icr\",   output = \"data.frame\" )  # Gold-standard validation, assuming coder1 is human gold standard res_gold <- validate(   data = my_df,   id   = \"doc_id\",   coder_cols  = c(\"coder1\", \"coder2\", \"llm1\", \"llm2\"),   mode = \"gold\",   gold = \"coder1\" ) } # }"},{"path":[]},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"the-quallmer-trail-0-2-0","dir":"Changelog","previous_headings":"","what":"The quallmer trail","title":"quallmer 0.2.0","text":"New qlm_trail() function extracts displays provenance chains coded objects, showing complete history coding runs including model parameters, timestamps, parent-child relationships. Export functions allow saving provenance trails: qlm_trail_save() RDS archival, qlm_trail_export() JSON format, qlm_trail_report() human-readable Quarto/RMarkdown documents. qlm_comparison qlm_validation objects now include run attributes capturing parent provenance, enabling full workflow traceability across comparisons validations. Provenance trail automatically captures branching workflows multiple coded objects compared validated.","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"new-api-0-2-0","dir":"Changelog","previous_headings":"","what":"New API","title":"quallmer 0.2.0","text":"package introduces new qlm_*() API richer return objects clearer terminology qualitative researchers: qlm_codebook() defines coding instructions, replacing task() (#27). qlm_code() executes coding tasks returns tibble coded results metadata attributes, replacing annotate() (#27). returned qlm_coded object prints tibble can used directly data manipulation workflows. Now includes name parameter tracking runs hierarchical attribute structure provenance support. qlm_compare() compares multiple qlm_coded objects assess inter-rater reliability. Automatically computes statistically appropriate measures irr package based specified measurement level (nominal, ordinal, interval). qlm_validate() validates qlm_coded object gold standard (human-coded reference data). Automatically computes statistically appropriate metrics based specified measurement level, using measures yardstick, irr, stats packages. nominal data, supports multiple averaging methods (macro, micro, weighted, per-class breakdown). qlm_replicate() re-executes coding optional overrides (model, codebook, parameters) tracking provenance chain. Enables systematic assessment coding reliability sensitivity model choices. new API uses qlm_ prefix avoid namespace conflicts (e.g., ggplot2::annotate()) follows convention verbs workflow actions, nouns accessor functions.","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"restructured-qlm_coded-objects-0-2-0","dir":"Changelog","previous_headings":"New API","what":"Restructured qlm_coded objects","title":"quallmer 0.2.0","text":"batch flag indicates whether batch processing used. execution_args replaces pcs_args stores non-chat execution arguments parallel batch processing. Old objects pcs_args remain compatible.","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"example-codebooks-0-2-0","dir":"Changelog","previous_headings":"","what":"Example codebooks","title":"quallmer 0.2.0","text":"New example codebook data objects provide ready--use codebooks common tasks: data_codebook_sentiment, data_codebook_stance, data_codebook_ideology, data_codebook_salience, data_codebook_fact. predefined task_*() functions deprecated favor using data objects creating custom codebooks qlm_codebook().","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"deprecated-and-superseded-functions-0-2-0","dir":"Changelog","previous_headings":"","what":"Deprecated and superseded functions","title":"quallmer 0.2.0","text":"task() deprecated favor qlm_codebook() (#27). annotate() deprecated favor qlm_code() (#27). validate() superseded qlm_compare() (inter-rater reliability) qlm_validate() (gold standard validation). function remains available marked lifecycle badge. Trail functions (trail_settings(), trail_record(), trail_compare(), trail_matrix(), trail_icr()) deprecated. Use qlm_code() model temperature parameters directly, qlm_replicate() systematic comparisons across models. Backward compatibility: Old code continues work deprecation warnings. New qlm_codebook objects work old annotate(), old task objects work new qlm_code(). achieved dual-class inheritance qlm_codebook inherits \"qlm_codebook\" \"task\".","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"package-restructuring-0-2-0","dir":"Changelog","previous_headings":"","what":"Package restructuring","title":"quallmer 0.2.0","text":"validate_app() extracted companion package quallmer.app. reduces dependencies core quallmer package (removing shiny, bslib, htmltools Imports). Install quallmer.app separately interactive validation functionality.","code":""},{"path":"https://seraphinem.github.io/quallmer/news/index.html","id":"other-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Other changes","title":"quallmer 0.2.0","text":"BREAKING: qlm_validate() now uses distinct, statistically appropriate metrics measurement level: Nominal (level = \"nominal\"): accuracy, precision, recall, F1-score, Cohen’s kappa (unweighted) Ordinal (level = \"ordinal\"): Spearman’s rho, Kendall’s tau, MAE (mean absolute error) Interval/Ratio (level = \"interval\"): ICC (intraclass correlation), Pearson’s r, MAE, RMSE (root mean squared error) measure argument removed entirely - appropriate measures now computed automatically based level parameter. Function signature changed: level now comes average, average applies nominal (multiclass) data. Return values renamed consistency: spearman → rho, kendall → tau, pearson → r. Print output uses “levels” terminology ordinal data “classes” nominal data. change provides statistically sound validation respects mathematical properties measurement scale. BREAKING: qlm_compare() now computes statistically appropriate measures measurement level: Nominal (level = \"nominal\"): Krippendorff’s alpha (nominal), Cohen’s/Fleiss’ kappa, percent agreement Ordinal (level = \"ordinal\"): Krippendorff’s alpha (ordinal), weighted kappa (2 raters ), Kendall’s W, Spearman’s rho, percent agreement Interval/Ratio (level = \"interval\"): Krippendorff’s alpha (interval), ICC (intraclass correlation), Pearson’s r, percent agreement measure argument removed entirely - appropriate measures now computed automatically returned result object. return structure changed single value list containing computed measures specified level. Percent agreement now computed levels; ordinal/interval/ratio data, tolerance parameter controls counts agreement (e.g., tolerance = 1 means values within 1 unit considered agreement). qlm_validate() qlm_compare() now support non-standard evaluation (NSE) argument, allowing = sentiment (unquoted) = \"sentiment\" (quoted) syntax. provides natural, tidyverse-style interface maintaining backward compatibility. Improved error messages qlm_compare() qlm_validate() now show objects missing requested variable list available alternatives. Adopt tidyverse-style error messaging via cli::cli_abort() cli::cli_warn() throughout package, replacing stop(), stopifnot(), warning() calls structured, informative error messages. Documentation CI notes refreshed.","code":""}]
