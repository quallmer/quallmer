% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/qlm_code.R
\name{qlm_code}
\alias{qlm_code}
\title{Code qualitative data with an LLM}
\usage{
qlm_code(.data, codebook, model_name, ...)
}
\arguments{
\item{.data}{Input data: a character vector of texts (for text codebooks) or
file paths to images (for image codebooks). Named vectors will use names
as identifiers in the output; unnamed vectors will use sequential integers.}

\item{codebook}{A codebook object created with \code{\link[=qlm_codebook]{qlm_codebook()}} or one of
the predefined codebook functions (\code{\link[=task_sentiment]{task_sentiment()}}, \code{\link[=task_stance]{task_stance()}},
\code{\link[=task_ideology]{task_ideology()}}, \code{\link[=task_salience]{task_salience()}}, \code{\link[=task_fact]{task_fact()}}). Also accepts
deprecated \code{\link[=task]{task()}} objects for backward compatibility.}

\item{model_name}{Provider (and optionally model) name in the form
\code{"provider/model"} or \code{"provider"} (which will use the default model for
that provider). Passed to the \code{name} argument of \code{\link[ellmer:chat-any]{ellmer::chat()}}.
Examples: \code{"openai/gpt-4o-mini"}, \code{"anthropic/claude-3-5-sonnet-20241022"},
\code{"ollama/llama3.2"}, \code{"openai"} (uses default OpenAI model).}

\item{...}{Additional arguments passed to either \code{\link[ellmer:chat-any]{ellmer::chat()}} or to
\code{\link[ellmer:parallel_chat]{ellmer::parallel_chat_structured()}}, based on argument name.
Arguments not recognized by either function will generate a warning.}
}
\value{
A \code{qlm_coded} object containing:
\describe{
\item{\code{codebook}}{The codebook used for coding.}
\item{\code{settings}}{Execution settings (model, additional parameters).}
\item{\code{results}}{Data frame with coded results (extract with \code{\link[=qlm_results]{qlm_results()}}).}
\item{\code{metadata}}{Metadata including timestamp, versions, number of units.}
}
}
\description{
Applies a codebook to input data using a large language model, returning
a rich object that includes the codebook, execution settings, results, and
metadata for reproducibility.
}
\details{
Arguments in \code{...} are dynamically routed to either \code{\link[ellmer:chat-any]{ellmer::chat()}} or to
\code{\link[ellmer:parallel_chat]{ellmer::parallel_chat_structured()}} based on their names.

Progress indicators and error handling are provided by the underlying
\code{\link[ellmer:parallel_chat]{ellmer::parallel_chat_structured()}} function. Set \code{verbose = TRUE} to see
progress messages during batch coding. Retry logic for API failures
should be configured through ellmer's options.
}
\examples{
\dontrun{
# Basic sentiment analysis
texts <- c("I love this product!", "This is terrible.")
coded <- qlm_code(texts, task_sentiment(), model_name = "openai")
qlm_results(coded)

# With named inputs (names become IDs in output)
texts <- c(doc1 = "Great service!", doc2 = "Very disappointing.")
coded <- qlm_code(texts, task_sentiment(), model_name = "openai")

# Specify provider and model
coded <- qlm_code(texts, task_sentiment(), model_name = "openai/gpt-4o-mini")

# With execution control
coded <- qlm_code(texts, task_sentiment(),
                  model_name = "openai/gpt-4o-mini",
                  max_active = 5)

# Include token usage
coded <- qlm_code(texts, task_sentiment(),
                  model_name = "openai",
                  include_tokens = TRUE)

# Inspect metadata
print(coded)
coded$settings
coded$metadata
}

}
\seealso{
\code{\link[=qlm_codebook]{qlm_codebook()}} for creating codebooks, \code{\link[=qlm_results]{qlm_results()}} for extracting results,
\code{\link[=task_sentiment]{task_sentiment()}}, \code{\link[=task_stance]{task_stance()}}, \code{\link[=task_ideology]{task_ideology()}}, \code{\link[=task_salience]{task_salience()}},
\code{\link[=task_fact]{task_fact()}} for predefined codebooks, \code{\link[=annotate]{annotate()}} for the deprecated function.
}
