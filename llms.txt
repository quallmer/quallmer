# quallmer

The **quallmer** package is an **easy-to-use toolbox for qualitative
researchers to quickly apply AI-assisted annotation to texts, images,
pdfs, tabular data and other structured data.**

Using
[`annotate()`](https://seraphinem.github.io/quallmer/reference/annotate.md),
users can generate structured, interpretable outputs powered by large
language models (LLMs). The package includes a library of [predefined
tasks for common qualitative coding
needs](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/overview.html),
such as sentiment analysis, thematic coding, and stance detection. It
also allows users to [create their own custom annotation tasks tailored
to their specific research questions and data
types](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html)
using
[`task()`](https://seraphinem.github.io/quallmer/reference/task.md). To
ensure quality and reliability of AI-generated annotations, **quallmer**
offers tools for comparing LLM outputs with human-coded data and
assessing inter-coder reliability. With `validation_app()`, users can
launch an interactive app to manually code data, review AI annotations,
and evaluate agreement between human and AI codings. The package also
includes a `trail_` functionality that enables systematic comparisons
across multiple LLM runs (“trails”) with different settings to ensure
reproducibility and reliability of AI-assisted coding.

**The quallmer package makes AI-assisted qualitative coding accessible
without requiring deep expertise in R, programming or machine
learning.**

# Core functions

The package provides the following core functions:

### `annotate()`

- A generic function that works with any LLM supported by
  [ellmer](https://ellmer.tidyverse.org/index.html).  
- Generates structured responses based on
  [predefined](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/overview.htmll)
  or [user-defined
  tasks](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.html).

### `task()`

- Creates custom annotation tasks tailored to specific research
  questions and data types.
- Uses `system_prompt` and various type specifications from the
  [ellmer](https://ellmer.tidyverse.org/reference/type_boolean.html)
  package to define how the LLM should interpret inputs and format
  outputs.  
- Tasks created with
  [`task()`](https://seraphinem.github.io/quallmer/reference/task.md)
  can be passed directly to
  [`annotate()`](https://seraphinem.github.io/quallmer/reference/annotate.md).  
- This allows users to tailor the annotation process to their specific
  data types and makes our package extensible for future use cases.

### `validate_app()`

- Launches an interactive app to
  - Manually code data
  - Review and validate LLM-generated annotations
  - Compare human-coded data with LLM-generated annotations to evaluate
    inter-coder reliability (e.g., Krippendorff’s alpha, Cohen’s or
    Fleiss’ kappa) or, if a gold standard is available, accuracy (e.g.,
    accuracy, precision, recall, F1-score).

### `validate()`

- Works similar to our validation app but can be used programmatically
  without launching the app if data has been already manually coded by
  humans.
- Has two modes:
  1.  **No gold standard available**: Compare LLM-generated annotations
      with multiple human coders to assess inter-coder reliability
      (e.g., Krippendorff’s alpha, Cohen’s or Fleiss’ kappa).
  2.  **Gold standard available**: Compare LLM-generated annotations
      against a human-coded gold standard to assess accuracy (e.g.,
      accuracy, precision, recall, F1-score).

# The quallmer trail [![quallmer website](reference/figures/paw.png)](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.html)

Apart from the core functions above, the **quallmer** package also
provides a set of functions to ensure reproducibility and reliability of
LLM-generated annotations through **systematic comparisons across
multiple LLM runs with different settings.** This “trail” functionality
adds a reproducibility layer on top of
[`annotate()`](https://seraphinem.github.io/quallmer/reference/annotate.md)
with the following workflow:

1.  **Define trail settings**  
    Describe the LLM trail, i.e., how LLMs should be called (e.g.,
    model, temperature).

    [`trail_settings()`](https://seraphinem.github.io/quallmer/reference/trail_settings.md)  
    ↓

2.  **Record single LLM trails for reproducibility**  
    Record all information needed for reproducing LLM runs on a given
    task with a specific setting.

    `trail_record(data, text_col, task, setting)`  
    ↓

3.  **Run multiple trails with different settings and assess
    sensitivity**  
    Run the *same* task and data across multiple settings (e.g.,
    different LLMs, different temperatures) and compute agreement across
    trails to illustrate reliability and replication sensitivity of LLM
    annotations.

    `trail_compare(data, text_col, task, settings = list(...))`

# Supported LLMs

The package supports all LLMs currently available with the `ellmer`
package. For authentication and usage of each of these LLMs, please
refer to the respective
[ellmer](https://ellmer.tidyverse.org/reference/index.html)
documentation and see our [tutorial for setting up an openai API
key](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.html)
or [getting started with an open-source Ollama
model](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/ollama.html).

## Installation

You can install the development version of **quallmer** from
<https://github.com/SeraphineM/quallmer> with:

``` r
# install.packages("pak")
pak::pak("SeraphineM/quallmer")
```

## Example use and tutorials

To learn more about how to use the package, please refer to our
[step-by-step
tutorials](https://seraphinem.github.io/quallmer/articles/getting-started.html)
and the illustrations on [how to use the predefined
tasks](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/overview.html).

# Package index

## All functions

- [`annotate()`](https://seraphinem.github.io/quallmer/reference/annotate.md)
  : Apply an annotation task to input data
- [`data_corpus_LMRDsample`](https://seraphinem.github.io/quallmer/reference/data_corpus_LMRDsample.md)
  : Sample from Large Movie Review Dataset (Maas et al. 2011)
- [`data_corpus_manifsentsUK2010sample`](https://seraphinem.github.io/quallmer/reference/data_corpus_manifsentsUK2010sample.md)
  : Sample of UK manifesto sentences 2010 crowd-annotated for
  immigration
- [`print(`*`<trail_settings>`*`)`](https://seraphinem.github.io/quallmer/reference/print.trail_settings.md)
  : Print method for trail_setting
- [`task()`](https://seraphinem.github.io/quallmer/reference/task.md) :
  Define an annotation task
- [`task_fact()`](https://seraphinem.github.io/quallmer/reference/task_fact.md)
  : Predefined task for overall truthfulness assessment
- [`task_ideology()`](https://seraphinem.github.io/quallmer/reference/task_ideology.md)
  : Predefined task for ideological scaling on a specified dimension
- [`task_salience()`](https://seraphinem.github.io/quallmer/reference/task_salience.md)
  : Predefined task for salience of topics discussed (ranked topics)
- [`task_sentiment()`](https://seraphinem.github.io/quallmer/reference/task_sentiment.md)
  : Predefined task for sentiment analysis
- [`task_stance()`](https://seraphinem.github.io/quallmer/reference/task_stance.md)
  : Predefined task for stance detection (position taking)
- [`trail_compare()`](https://seraphinem.github.io/quallmer/reference/trail_compare.md)
  : trail_compare: run a task across multiple settings and compute
  reliability
- [`trail_icr()`](https://seraphinem.github.io/quallmer/reference/trail_icr.md)
  : Compute intercoder reliability across Trail settings
- [`trail_matrix()`](https://seraphinem.github.io/quallmer/reference/trail_matrix.md)
  : Convert Trail records to coder-style wide data
- [`trail_record()`](https://seraphinem.github.io/quallmer/reference/trail_record.md)
  : Trail record: reproducible quallmer annotation
- [`trail_settings()`](https://seraphinem.github.io/quallmer/reference/trail_settings.md)
  : Trail settings specification
- [`validate()`](https://seraphinem.github.io/quallmer/reference/validate.md)
  : Validate coding: intercoder reliability or gold-standard comparison
- [`validate_app()`](https://seraphinem.github.io/quallmer/reference/validate_app.md)
  : Launch the Validate App

# Articles

### All vignettes

- [Defining custom
  tasks](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/customtask.md):
- [Getting started with
  quallmer](https://seraphinem.github.io/quallmer/articles/getting-started.md):
- [Working with an open-source Ollama
  model](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/ollama.md):
- [Signing up for an openai API
  key](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/openai.md):
- [Overview of predefined
  tasks](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/overview.md):
- [Using predefined
  tasks](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/predefined.md):
- [Example: Fact checking of
  claims](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_fact.md):
- [Example: Ideology
  detection](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_ideology.md):
- [Example: Salience of
  topics](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_salience.md):
- [Example: Sentiment
  analysis](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_sentiment.md):
- [Example: Stance
  detection](https://seraphinem.github.io/quallmer/articles/pkgdown/examples/task_stance.md):
- [The quallmer
  trail](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/trail.md):
- [Using the Validate
  App](https://seraphinem.github.io/quallmer/articles/pkgdown/tutorials/validate.md):
